{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Greedy (arc-standard) Transition Dependency Parser\n",
    "\n",
    "We will now use the trained neural oracle to perform (arc-standard) dependency parsing. Given a sentence, we initialize a buffer containing the words and punctuation symbols of the sentence, a stack containing the `ROOT` and an empty dependency relations list. Starting from this initial state, we perform parse steps by applying actions chosen by the oracle and updating the system state. When the terminal state is reached (i.e. the buffer is empty and the stack only contains the `ROOT`), the complete dependency parse is contained in the dependency relations list.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from parse_utils import *\n",
    "import wandb\n",
    "import pickle \n",
    "\n",
    "wandb.login()\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets load the validation set data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in the validation data: 1700\n"
     ]
    }
   ],
   "source": [
    "data_val = read_conllu(os.path.join('data', 'dev.conll'))\n",
    "print(f\"Number of sentences in the validation data: {len(data_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pytorch dataset object from file\n",
    "with open('val_dataset_pytorch.pkl', 'rb') as f:\n",
    "    val_dataset = pickle.load(f)\n",
    "\n",
    "action2idx = val_dataset.action2idx\n",
    "label2idx = val_dataset.label2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the trained oracle model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from checkpoint!\n",
      "Total number of parameters in transformer network: 66.959019 M\n",
      "RAM used: 2707.07 MB\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\"\n",
    "learning_rate = 1e-5\n",
    "model = BERT_ORACLE(num_actions=len(action2idx), num_labels=len(label2idx), unlabeled_arcs=False).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "model, optimizer = load_model_checkpoint(model, optimizer)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters in transformer network: {num_params/1e6} M\")\n",
    "print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2752455174922943, 0.9773752207663278, 0.9538105168222937)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, collate_fn=collate_fn)\n",
    "validation(model, val_dataloader, device=DEVICE)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets implement the greedy arc-standard transition parser. This implementation is very strict and causes parser to fail whenever oracle predicts an invalid action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Greedy arc-standard transition parser\n",
    "\"\"\"\n",
    "def parser(sentence_words, oracle, dataset, verbose=False):\n",
    "    tokens = [(word, i+1) for i,word in enumerate(sentence_words)]\n",
    "\n",
    "    # initialize the state\n",
    "    stack = [('ROOT', 0)]\n",
    "    buffer = tokens.copy()\n",
    "    arcs = []\n",
    "\n",
    "    # convert sentence to model input tensors\n",
    "    input_idx, input_attn_mask, word_ids = dataset.tokenize_sentence(sentence_words)\n",
    "    input_idx = input_idx.unsqueeze(0).to(DEVICE)\n",
    "    input_attn_mask = input_attn_mask.unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    # set model to eval mode\n",
    "    oracle.eval()\n",
    "    # compute BERT encoding of sentence tokens\n",
    "    with torch.no_grad():\n",
    "        bert_output = oracle.get_bert_encoding(input_idx, input_attn_mask)\n",
    "\n",
    "    labels = list(dataset.label2idx.keys())\n",
    "    actions = list(dataset.action2idx.keys())\n",
    "\n",
    "    if verbose: \n",
    "            print(f\"\\nStack: {stack}\")\n",
    "            print(f\"Buffer: {buffer}\")   \n",
    "\n",
    "    # begin parsing\n",
    "    while len(buffer) > 0 or len(stack) > 1:\n",
    "\n",
    "        if len(buffer) > 0:\n",
    "            state = [(stack[-2:] , buffer[0])]\n",
    "        else:\n",
    "            state = [(stack[-2:], None)]\n",
    "        state_idx = [dataset.tokenize_state(state, word_ids)]    \n",
    "\n",
    "        # get the oracle action and label scores\n",
    "        action_logits, label_logits = oracle.predict(bert_output, state_idx)\n",
    "        \n",
    "        # pick highest scoring action and label\n",
    "        best_action = actions[torch.argmax(action_logits[0][0])]\n",
    "        best_label = labels[torch.argmax(label_logits[0][0])]\n",
    "\n",
    "        # perform the action\n",
    "        if best_action == 'LEFTARC':\n",
    "            # LEFTARC\n",
    "            if len(stack) > 1:\n",
    "                if stack[-2][0] != 'ROOT':\n",
    "                    arcs.append((stack[-1], stack[-2], best_label))\n",
    "                    stack.pop(-2)\n",
    "                else:\n",
    "                    raise ValueError(\"Cannot perform LEFTARC action with ROOT as dependent. Parse failed.\")    \n",
    "            else:\n",
    "                raise ValueError(\"Cannot perform LEFTARC action with stack length <= 1. Parse failed.\")\n",
    "\n",
    "        elif best_action == 'RIGHTARC':\n",
    "            # RIGHTARC\n",
    "            if len(stack) > 1:\n",
    "                arcs.append((stack[-2], stack[-1], best_label))\n",
    "                stack.pop(-1) \n",
    "            else:\n",
    "                raise ValueError(\"Cannot perform RIGHTARC action with stack length <= 1. Parse failed.\")         \n",
    "\n",
    "        else:\n",
    "            # SHIFT\n",
    "            if len(buffer) > 0:\n",
    "                stack.append(buffer.pop(0))\n",
    "            else:\n",
    "                raise ValueError(\"Cannot perform SHIFT action with buffer length <= 0. Parse failed.\")         \n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Best action: {best_action}, best label: {best_label}\")\n",
    "            print(f\"\\nStack: {stack}\")\n",
    "            print(f\"Buffer: {buffer}\")\n",
    "            print(f\"Arcs: {arcs}\")        \n",
    "\n",
    "    return arcs                       \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Evaluate the predicted arcs against the gold arcs by computing unlabeled and labeled attachment scores\n",
    "\"\"\"\n",
    "def evaluate(gold_arcs, predicted_arcs):\n",
    "    uas = 0\n",
    "    las = 0\n",
    "    gold_head_deps = [(r[0], r[1]) for r in gold_arcs]\n",
    "\n",
    "    for r in predicted_arcs:\n",
    "        if (r[0], r[1]) in gold_head_deps:\n",
    "            uas += 1\n",
    "            if r in gold_arcs:\n",
    "                las += 1\n",
    "\n",
    "    uas = uas / len(gold_arcs)\n",
    "    las = las / len(gold_arcs)            \n",
    "    return uas, las    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a test sentence from the validation set and its gold standard parse\n",
    "test_data_instance = data_val[10]\n",
    "gold_states, gold_actions, gold_labels, sentence_words, gold_arcs  = training_oracle(test_data_instance, return_states=True, max_iters=100000)\n",
    "\n",
    "# predict the parse using the oracle\n",
    "precicted_arcs = parser(sentence_words, model, val_dataset, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UAS: 1.0, LAS: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# compare the gold standard and predicted arcs\n",
    "uas, las = evaluate(gold_arcs, precicted_arcs)\n",
    "print(f\"UAS: {uas}, LAS: {las}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
