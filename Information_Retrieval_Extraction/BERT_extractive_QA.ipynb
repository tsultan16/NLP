{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finetuning BERT for `Extractive Question Answering` \n",
    "\n",
    "We will finetune a BERT model on the task of extractive QA, which involves taking a `factoid question` and a `context passage` of text and `labeling a span` of text from that passage which contains the `answer`. We can frame this as a `classification task`. First we concatenate the question and context passage pair, seperated by a `[SEP]` token. Then we compute the BERT encoding for this sequence. Then we apply a linear transform to each output token's encoding vector to compute a scalar score. By passing the scores from all tokens through a softmax, we obtain a `probability distribution` over tokens in the sequence, which we can interpret as the probability of a token being the start of the span. We actually will compute two separate linear transforms of all tokens and pass both sets of scores through a softmax to get two probability distributions over tokens, one for `start of span` and one for `end of span`. \n",
    "\n",
    "We will train this model on the SQuAD v1 dataset which contains passages with multiple questions and answer span pairs. We will use the cross entropy loss at the softmax output. To make predictions, we can simply just add up the scores of the `ith` token being the start and the `jth` token being the end for all i and j>i, then declare the (i,j) with the highest score as the predicted span.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtanzids\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import csv\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "import json\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load the data from file and then set up pytorch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train and dev JSON documents\n",
    "with open(\"train.json\", \"r\") as train_file:\n",
    "    squad_train = json.load(train_file)         \n",
    "with open(\"dev.json\", \"r\") as dev_file:\n",
    "    squad_dev = json.load(dev_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_passages(squad, num_titles=None):\n",
    "    if num_titles is None:\n",
    "        num_titles = len(squad['data'])\n",
    "    # for each title, get passages and all corresponding questions from SQuAD train set\n",
    "    passages = []\n",
    "    questions = []\n",
    "    num_questions = 0\n",
    "    for i in range(num_titles):\n",
    "        #print(f\"Title# {i}: {squad['data'][i]['title']}, Number of passages: {len(squad['data'][i]['paragraphs'])}\")\n",
    "        for p in squad['data'][i]['paragraphs']:\n",
    "            # we will append the title to each passage and question\n",
    "            passages.append(p['context'])\n",
    "            questions.append([q for q in p['qas']])    \n",
    "            num_questions += len(p['qas'])\n",
    "    print(f\"Number of passages: {len(passages)}\")\n",
    "    print(f\"Number of questions: {num_questions}\")\n",
    "    return passages, questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of passages: 19035\n",
      "Number of questions: 130319\n",
      "Number of passages: 1204\n",
      "Number of questions: 11873\n"
     ]
    }
   ],
   "source": [
    "passages_train, questions_train = get_passages(squad_train)\n",
    "passages_val, questions_val = get_passages(squad_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max passage length: 3706, Avg passage length: 735.5478854741266\n"
     ]
    }
   ],
   "source": [
    "passage_lengths = [len(p) for p in passages_train]\n",
    "print(f\"Max passage length: {max(passage_lengths)}, Avg passage length: {sum(passage_lengths)/len(passage_lengths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the context passaged are very long (over 700 words on average) and won't fit into our BERT model (which can only take upto 512 tokens per sequence). So we will instead take a shorter fixed size context window for each question.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many awards was Beyonce nominated for at the 52nd Grammy Awards?\n",
      "Answer span: ten\n"
     ]
    }
   ],
   "source": [
    "q = questions_train[16][0]\n",
    "answer_start_pos = q['answers'][0]['answer_start']\n",
    "answer_end_pos = answer_start_pos + len(q['answers'][0]['text'])\n",
    "context = passages_train[16]\n",
    "\n",
    "print(f\"Question: {q['question']}\")\n",
    "print(f\"Answer span: {context[answer_start_pos:answer_end_pos]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context window:  At the 52nd Annual Grammy Awards, Beyoncé received ten nominations, including Album of the Year for I Am... Sasha Fierce, Record of the Year for \"Halo\", and Song of the Year for \"Single Ladies (Put a Ring on It)\", among others. She tied with Lauryn Hill for most Grammy nominations in a single year by a female artist. In 2010, Beyoncé was featured on Lady Gaga's single \"Telephone\" and its music video. The song topped the US Pop Songs chart, becoming the sixth number-one for both Beyoncé and Gaga,\n",
      "Answer window: ten\n",
      "Answer window trimmed: ten\n"
     ]
    }
   ],
   "source": [
    "window_size_chars = 500\n",
    "# pick a random context window around the answer (try to keep at least 40% of the characters in window on the left side of the answer)\n",
    "answer_middle_pos = int((answer_start_pos+answer_end_pos)/2) \n",
    "a = max(0,answer_end_pos-window_size_chars)\n",
    "b = max(0, answer_start_pos - 0.4*window_size_chars)\n",
    "random_window_start_pos = random.randint(a, b)\n",
    "#window_start_pos = max(0,answer_middle_pos-window_size_chars)\n",
    "#window_end_pos = answer_middle_pos+window_size_chars\n",
    "window_start_pos = random_window_start_pos\n",
    "window_end_pos = window_start_pos+window_size_chars\n",
    "\n",
    "context_window = context[window_start_pos:window_end_pos]\n",
    "print(\"Context window: \", context_window)\n",
    "\n",
    "answer_start_pos_window = answer_start_pos - window_start_pos\n",
    "answer_end_pos_window = answer_start_pos_window + len(q['answers'][0]['text'])\n",
    "answer_window = context_window[answer_start_pos_window:answer_end_pos_window]\n",
    "print(f\"Answer window: {answer_window}\")\n",
    "\n",
    "# Trim off stray partial words at the beginning and end\n",
    "context_window_words = context_window.split()\n",
    "# only trim if the first stray word does not overlap with the answer span\n",
    "if answer_start_pos_window > len(context_window_words[0]):\n",
    "    context_window = ' '.join(context_window_words[1:-1])\n",
    "    left_trim_length = len(context_window_words[0]) + 1 # add 1 for the white space between stary partial first word and next word\n",
    "    answer_start_pos_window = answer_start_pos_window - left_trim_length\n",
    "    answer_end_pos_window = answer_end_pos_window - left_trim_length\n",
    "\n",
    "answer_window = context_window[answer_start_pos_window:answer_end_pos_window]\n",
    "print(f\"Answer window trimmed: {answer_window}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will use WordPiece tokenization, we need to be careful about converting the character positions of the start and end of the span to subwork token positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping'])\n",
      "Decoded subword token span: ten\n",
      "Decoded sentence pair: [CLS] the 52nd annual grammy awards, beyonce received ten nominations, including album of the year for i am... sasha fierce, record of the year for \" halo \", and song of the year for \" single ladies ( put a ring on it ) \", among others. she tied with lauryn hill for most grammy nominations in a single year by a female artist. in 2010, beyonce was featured on lady gaga's single \" telephone \" and its music video. the song topped the us pop songs chart, becoming the sixth number - one for both beyonce and [SEP] how many awards was beyonce nominated for at the 52nd grammy awards? [SEP]\n"
     ]
    }
   ],
   "source": [
    "# encode the passage\n",
    "context_encoded = tokenizer.encode_plus((context_window, q['question']), add_special_tokens=True, return_offsets_mapping=True)\n",
    "print(context_encoded.keys())\n",
    "# convert character positions from original sentence to subword token positions\n",
    "start_pos_enc = context_encoded.char_to_token(answer_start_pos_window)\n",
    "end_pos_enc = context_encoded.char_to_token(answer_end_pos_window-1)\n",
    "# get the corresponding subword token span\n",
    "answer_span_encoded = context_encoded['input_ids'][start_pos_enc:end_pos_enc+1]\n",
    "# decode the span to check if it matches original answer span\n",
    "print(f\"Decoded subword token span: {tokenizer.decode(answer_span_encoded)}\")\n",
    "print(f\"Decoded sentence pair: {tokenizer.decode(context_encoded['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create question, trimmed context window and answer span instances. Note: some quesitions may contain empty answers list, those will be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for creating instances\n",
    "def get_instances(passages, questions, window_size_chars=400):\n",
    "    triplets = []\n",
    "    for i, context in enumerate(passages):\n",
    "        for q in questions[i]:\n",
    "            for a in q['answers']:\n",
    "                # get start and end character positions of answer span \n",
    "                answer_start_pos = a['answer_start']\n",
    "                answer_end_pos = answer_start_pos + len(a['text'])\n",
    "                # get windowed context\n",
    "                a = max(0,answer_end_pos-window_size_chars)\n",
    "                b = max(0, answer_start_pos - 0.4*window_size_chars)\n",
    "                window_start_pos = random.randint(a, b)\n",
    "                window_end_pos = window_start_pos+window_size_chars\n",
    "                context_window = context[window_start_pos:window_end_pos]\n",
    "                # offset the answer span positions\n",
    "                answer_start_pos_window = answer_start_pos - window_start_pos\n",
    "                answer_end_pos_window = answer_start_pos_window + len(q['answers'][0]['text'])\n",
    "                # Trim off stray partial words at the beginning and end of window\n",
    "                context_window_words = context_window.split()\n",
    "                # only trim if the first stray word does not overlap with the answer span\n",
    "                \"\"\"\n",
    "                if answer_start_pos_window > len(context_window_words[0]):\n",
    "                    context_window = ' '.join(context_window_words[1:-1])\n",
    "                    left_trim_length = len(context_window_words[0]) + 1 # add 1 for the white space between stary partial first word and next word\n",
    "                    answer_start_pos_window = answer_start_pos_window - left_trim_length\n",
    "                    answer_end_pos_window = answer_end_pos_window - left_trim_length\n",
    "                \"\"\"    \n",
    "                if (answer_start_pos_window < 0) or (answer_end_pos_window < 0) or (answer_end_pos_window < answer_start_pos_window):\n",
    "                    print(f\"Context: {context}\")\n",
    "                    print(f\"Question: {q}\")\n",
    "                    print(f\"answer_start_pos: {answer_start_pos}, answer_end_pos: {answer_end_pos}\")    \n",
    "                    print(f\"context char length: {len(context)}, window start pos: {window_start_pos}, window end pos: {window_end_pos}\")\n",
    "                    print(f\"answer start pos window: {answer_start_pos_window}, answer end pos window: {answer_end_pos_window}\")    \n",
    "                    print(f\"Context trimmed: {context_window}\")\n",
    "                    raise Exception(f\"Trimmed answer span is negative! start_pos: {answer_start_pos_window}, end_pos: {answer_end_pos_window}\")\n",
    "                \n",
    "                triplets.append(((context_window, q['question']), answer_start_pos_window, answer_end_pos_window))\n",
    "    return triplets            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets_train = get_instances(passages_train, questions_train)\n",
    "triplets_val = get_instances(passages_val, questions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((\"d performances have led to critics hailing her as one of the best entertainers in contemporary popular music. Throughout a career spanning 19 years, she has sold over 118 million records as a solo artist, and a further 60 million with Destiny's Child, making her one of the best-selling music artists of all time. She has won 20 Grammy Awards and is the most nominated woman in the award's history. T\",\n",
       "  'How many Grammy awards has Beyoncé won?'),\n",
       " 326,\n",
       " 328)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets_train[37]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set up a pytorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadDataset(Dataset):\n",
    "    def __init__(self, data, max_length=256):\n",
    "        self.data = data\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get the data instance\n",
    "        sentence_pair = self.data[idx][0]\n",
    "        start_pos_char = self.data[idx][1]\n",
    "        end_pos_char = self.data[idx][2]\n",
    "        # encode the sentences\n",
    "        encoded = self.tokenizer.encode_plus(\n",
    "            sentence_pair,\n",
    "            add_special_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",  # Pad to the maximum length\n",
    "            max_length=self.max_length  # Set the maximum length\n",
    "        )\n",
    "        # get the token indices and attention mask\n",
    "        input_idx = encoded['input_ids']\n",
    "        attn_mask = encoded['attention_mask']\n",
    "        # convert start and end character positions to subword token positions\n",
    "        start_pos_enc = encoded.char_to_token(start_pos_char)\n",
    "        end_pos_enc = encoded.char_to_token(end_pos_char-1)\n",
    "        if (start_pos_enc is None) or (end_pos_enc is None):\n",
    "            print(f\"start pos char: {start_pos_char}, end pos char: {end_pos_char}\")\n",
    "            print(f\"decoded sentence pair: {self.tokenizer.decode(input_idx)}\")\n",
    "            print(f\"answer span: {sentence_pair[0][start_pos_char:end_pos_char]}\")\n",
    "            raise Exception(f\"Start or end position is None! start_pos: {start_pos_enc}, end_pos: {end_pos_enc}\")\n",
    "        if len(input_idx) != self.max_length:\n",
    "            raise Exception(f\"Encoded input sequence length {len(input_idx)} is not equal to max_length {self.max_length}!\")\n",
    "\n",
    "        # convert to tensors\n",
    "        input_idx = torch.tensor(input_idx)\n",
    "        attn_mask = torch.tensor(attn_mask)\n",
    "        start_pos_enc = torch.tensor(start_pos_enc)\n",
    "        end_pos_enc = torch.tensor(end_pos_enc)\n",
    "        return input_idx, start_pos_enc, end_pos_enc, attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SquadDataset(triplets_train)\n",
    "val_dataset = SquadDataset(triplets_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now define the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTExtractiveQA(torch.nn.Module):\n",
    "    def __init__(self, hidden_size=768, dropout_rate=0.1, finetune=False):\n",
    "        super().__init__()\n",
    "        # load pretrained BERT model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)      \n",
    "        # define two classifier heads, one for predicting start of span and another for end of span \n",
    "        self.classifier_head_start_span = torch.nn.Linear(hidden_size, 1)\n",
    "        self.classifier_head_end_span = torch.nn.Linear(hidden_size, 1)\n",
    "\n",
    "        for param in self.bert.parameters():\n",
    "            if finetune:\n",
    "                # make all parameters of BERT model trainable if we're finetuning\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                # freeze all parameters of BERT model if we're not finetuning\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_idx, labels_start, labels_end, attn_mask):\n",
    "        # compute BERT encodings\n",
    "        bert_output = self.bert(input_idx, attention_mask=attn_mask)\n",
    "        bert_output = bert_output.last_hidden_state # shape: (batch_size, sequence_length, hidden_size)\n",
    "        # compute logits/scores over tokens for each of the classifier heads\n",
    "        logits_start = self.classifier_head_start_span(bert_output).squeeze(-1)  # shape: (batch_size, sequence_length)\n",
    "        logits_end = self.classifier_head_end_span(bert_output).squeeze(-1)  # shape: (batch_size, sequence_length)\n",
    "        # compute loss\n",
    "        loss = F.cross_entropy(logits_start, labels_start) + F.cross_entropy(logits_end, labels_end) \n",
    "\n",
    "        return logits_start, logits_end, loss\n",
    "    \n",
    "\n",
    "# training loop\n",
    "def train(model, optimizer, train_dataloader, val_dataloader, scheduler=None, device=\"cpu\", num_epochs=10, val_every=1, save_every=None, log_metrics=None):\n",
    "    avg_loss = 0\n",
    "    train_acc = 0\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        num_correct = 0\n",
    "        num_total = 0\n",
    "        pbar = tqdm(train_dataloader, desc=\"Epochs\")\n",
    "        for batch in pbar:\n",
    "            inputs, targets_start, targets_end, attn_mask = batch\n",
    "            # move batch to device\n",
    "            inputs, targets_start, targets_end, attn_mask = inputs.to(device), targets_start.to(device), targets_end.to(device), attn_mask.to(device)\n",
    "            # forward pass\n",
    "            logits_start, logits_end, loss = model(inputs, targets_start, targets_end, attn_mask)\n",
    "            # reset gradients\n",
    "            optimizer.zero_grad()\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            # optimizer step\n",
    "            optimizer.step()\n",
    "            avg_loss = 0.9* avg_loss + 0.1*loss.item()\n",
    "            B, _ = inputs.shape\n",
    "            y_pred_start = logits_start.argmax(dim=-1).view(-1) # shape (B,)\n",
    "            y_pred_end = logits_end.argmax(dim=-1).view(-1) # shape (B,)\n",
    "            num_correct += ((y_pred_start.eq(targets_start.view(-1)) + y_pred_end.eq(targets_end.view(-1))) == 2).sum().item()            \n",
    "            num_total += B\n",
    "            train_acc = num_correct / num_total        \n",
    "            \n",
    "            pbar.set_description(f\"Epoch {epoch + 1}, EMA Train Loss: {avg_loss:.3f}, Train Accuracy: {train_acc: .3f}, Val Loss: {val_loss: .3f}, Val Accuracy: {val_acc: .3f}\")  \n",
    "\n",
    "            if log_metrics:\n",
    "                metrics = {\"Batch loss\" : loss.item(), \"Moving Avg Loss\" : avg_loss, \"Val Loss\": val_loss}\n",
    "                log_metrics(metrics)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        if val_every is not None:\n",
    "            if epoch%val_every == 0:\n",
    "                # compute validation loss\n",
    "                val_loss, val_acc = validation(model, val_dataloader, device=device)\n",
    "                pbar.set_description(f\"Epoch {epoch + 1}, EMA Train Loss: {avg_loss:.3f}, Train Accuracy: {train_acc: .3f}, Val Loss: {val_loss: .3f}, Val Accuracy: {val_acc: .3f}\") \n",
    "\n",
    "        if save_every is not None:\n",
    "            if (epoch+1) % save_every == 0:\n",
    "                save_model_checkpoint(model, optimizer, epoch, avg_loss)\n",
    "\n",
    "\n",
    "def validation(model, val_dataloader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    val_losses = torch.zeros(len(val_dataloader))\n",
    "    with torch.no_grad():\n",
    "        num_correct = 0\n",
    "        num_total = 0\n",
    "        for i,batch in enumerate(val_dataloader):\n",
    "            inputs, targets_start, targets_end, attn_mask = batch\n",
    "            inputs, targets_start, targets_end, attn_mask = inputs.to(device), targets_start.to(device), targets_end.to(device), attn_mask.to(device)\n",
    "            logits_start, logits_end, loss = model(inputs, targets_start, targets_end, attn_mask)\n",
    "            B, _ = inputs.shape\n",
    "            y_pred_start = logits_start.argmax(dim=-1).view(-1) # shape (B,)\n",
    "            y_pred_end = logits_end.argmax(dim=-1).view(-1) # shape (B,)\n",
    "            num_correct += ((y_pred_start.eq(targets_start.view(-1)) + y_pred_end.eq(targets_end.view(-1))) == 2).sum().item()            \n",
    "            num_total += B\n",
    "            val_losses[i] = loss.item()\n",
    "    model.train()\n",
    "    val_loss = val_losses.mean().item()\n",
    "    val_accuracy = num_correct / num_total\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "\n",
    "def save_model_checkpoint(model, optimizer, epoch=None, loss=None, filename=None):\n",
    "    # Save the model and optimizer state_dict\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }\n",
    "\n",
    "    # Save the checkpoint to a file\n",
    "    if filename:\n",
    "        torch.save(checkpoint, filename)\n",
    "    else:\n",
    "        torch.save(checkpoint, 'qa_checkpoint.pth')\n",
    "    print(f\"Saved model checkpoint!\")\n",
    "\n",
    "\n",
    "def load_model_checkpoint(model, optimizer, filename=None):\n",
    "    if filename:\n",
    "        checkpoint = torch.load(filename)\n",
    "    else:\n",
    "        checkpoint = torch.load('qa_checkpoint.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    model.train()\n",
    "    print(\"Loaded model from checkpoint!\")\n",
    "    return model, optimizer             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the model with and without finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in transformer network: 109.483778 M\n",
      "RAM used: 6661.90 MB\n"
     ]
    }
   ],
   "source": [
    "block_size = 256\n",
    "B = 64\n",
    "DEVICE = \"cuda\"\n",
    "learning_rate = 5e-3\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=B, shuffle=True) #, pin_memory=True, num_workers=2)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=B, shuffle=True) #, pin_memory=True, num_workers=2)\n",
    "\n",
    "# model with finetuning disabled\n",
    "model = BERTExtractiveQA(finetune=False).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler =  torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.95)\n",
    "#model, optimizer = load_model_checkpoint(model, optimizer)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters in transformer network: {num_params/1e6} M\")\n",
    "print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 256]) torch.Size([64]) torch.Size([64]) torch.Size([64, 256])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets_start, targets_end, attn_mask = next(iter(train_dataloader))\n",
    "\n",
    "print(inputs.shape, targets_start.shape, targets_end.shape, attn_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/1357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits start shape: torch.Size([64, 256]), labels start shape: torch.Size([64])\n",
      "logits end shape: torch.Size([64, 256]), labels end shape: torch.Size([64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, EMA Train Loss: 1.113, Train Accuracy:  0.000, Val Loss:  0.000, Val Accuracy:  0.000:   0%|          | 1/1357 [00:00<11:56,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits start shape: torch.Size([64, 256]), labels start shape: torch.Size([64])\n",
      "logits end shape: torch.Size([64, 256]), labels end shape: torch.Size([64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, EMA Train Loss: 2.055, Train Accuracy:  0.000, Val Loss:  0.000, Val Accuracy:  0.000:   0%|          | 2/1357 [00:01<11:34,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits start shape: torch.Size([64, 256]), labels start shape: torch.Size([64])\n",
      "logits end shape: torch.Size([64, 256]), labels end shape: torch.Size([64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, EMA Train Loss: 2.841, Train Accuracy:  0.000, Val Loss:  0.000, Val Accuracy:  0.000:   0%|          | 3/1357 [00:01<11:29,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits start shape: torch.Size([64, 256]), labels start shape: torch.Size([64])\n",
      "logits end shape: torch.Size([64, 256]), labels end shape: torch.Size([64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, EMA Train Loss: 3.522, Train Accuracy:  0.000, Val Loss:  0.000, Val Accuracy:  0.000:   0%|          | 4/1357 [00:02<11:26,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits start shape: torch.Size([64, 256]), labels start shape: torch.Size([64])\n",
      "logits end shape: torch.Size([64, 256]), labels end shape: torch.Size([64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, EMA Train Loss: 4.091, Train Accuracy:  0.000, Val Loss:  0.000, Val Accuracy:  0.000:   0%|          | 5/1357 [00:02<11:24,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits start shape: torch.Size([64, 256]), labels start shape: torch.Size([64])\n",
      "logits end shape: torch.Size([64, 256]), labels end shape: torch.Size([64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, EMA Train Loss: 4.091, Train Accuracy:  0.000, Val Loss:  0.000, Val Accuracy:  0.000:   0%|          | 5/1357 [00:03<13:45,  1.64it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[0;32mIn[58], line 57\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_dataloader, val_dataloader, scheduler, device, num_epochs, val_every, save_every, log_metrics)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# optimizer step\u001b[39;00m\n\u001b[1;32m     56\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 57\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m\u001b[38;5;241m*\u001b[39m avg_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.1\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m B, _ \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     59\u001b[0m y_pred_start \u001b[38;5;241m=\u001b[39m logits_start\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# shape (B,)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, optimizer, train_dataloader, val_dataloader, device=DEVICE, num_epochs=1, save_every=50, val_every=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
