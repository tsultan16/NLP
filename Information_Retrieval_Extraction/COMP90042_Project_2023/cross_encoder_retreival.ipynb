{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Encoder Passage Retrieval Model\n",
    "\n",
    "We will now explore an alternative mnodel for document retreival, called a `cross-encoder`. Unlike the bi-encoder, we will use a single BERT model and feed it input sequence which is a concatenation of a claim-passage pair. Then using the output embedding of the [CLS] token, we perform a `binary classification` of whether or not, the passage is relevant to this claim or not. We can set up training instances of both positive/relevant and negative/non-relevant pairs and train using binary cross-entropy loss. Then the sigmoid of the output logit can be interpreted as a relevancy score between $[0,1]$. \n",
    "\n",
    "Since each claim can have multiple relevant evidence passages, we can create multiple positive pairs. Then to have a balanced distribution of the two classes, we would also create the same number of negative pairs. However, we need to figure out a way to select the negative passages. The simplest way is to just `randomly sample` a passage from the document store which is also not in the list of positive passages. Howerever, these random samples may be too easy for our model to detect, and so ideally we would want to use some form of `hard-negative mining` to select good negative passages. \n",
    "\n",
    "So first, lets set up our dataset and implement hard-negative mining. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtanzids\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from collections import Counter\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "from utils import *\n",
    "from DPR_biencoder_simple import *\n",
    "import wandb\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "wandb.login()\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of evidence passages: 1208827\n",
      "Number of training instances: 1228\n",
      "Number of validation instances: 154\n",
      "Number of evidence passages remaining after cleaning: 1190647\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "document_store, train_data, val_data = load_data(clean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard-negative Mining: We will use our pre-trained dpr model to mine for hard negatives. We will retrieve the top-k passages for each training query and then sample hard negatives from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from checkpoint!\n"
     ]
    }
   ],
   "source": [
    "# load pretrained dpr model\n",
    "DEVICE = \"cuda\"\n",
    "model = BERTBiEncoder().to(DEVICE)\n",
    "model = load_dpr_model_checkpoint(model)\n",
    "\n",
    "# load dpr passage embeddings\n",
    "evidence_passage_embeds, passage_ids = load_dpr_passage_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "block_size = 196\n",
    "\n",
    "# now get the hard negatives for each question\n",
    "def get_hard_negatives(dpr_model, tokenizer, data, passage_ids, block_size, k=100):\n",
    "    \"\"\"\n",
    "    Get the k hard negatives for each claim in the dataset\n",
    "    \"\"\"\n",
    "    claims_list = list(data.items()) \n",
    "    hard_negatives = {}\n",
    "    for claim_id, claim in tqdm(claims_list):\n",
    "        claim_text = claim[\"claim_text\"]\n",
    "        gold_evidence_list = claim[\"evidences\"]\n",
    "        topk_passage_ids, topk_scores = find_topk_evidence_dpr(dpr_model, tokenizer, claim_text, evidence_passage_embeds, passage_ids, block_size, k=k)\n",
    "        # remove the gold evidence from the topk passages\n",
    "        topk_passage_ids = [p_id for p_id in topk_passage_ids if p_id not in gold_evidence_list]\n",
    "        hard_negatives[claim_id] = topk_passage_ids\n",
    "\n",
    "    return hard_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [00:27<00:00, 44.10it/s]\n"
     ]
    }
   ],
   "source": [
    "train_hard_negatives = get_hard_negatives(model, tokenizer, train_data, passage_ids, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [00:03<00:00, 41.33it/s]\n"
     ]
    }
   ],
   "source": [
    "val_hard_negatives = get_hard_negatives(model, tokenizer, val_data, passage_ids, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claim: an airplane is contributing to the emissions that put the frozen continent at risk.\n",
      "\n",
      "Gold evidence: \n",
      "\tThis enables the entire craft to contribute to lift generation with the result of potentially increased fuel economy.\n",
      "\tThe airline industry is responsible for about 11% of greenhouse gases emitted by the U.S. transportation sector.\n",
      "\tAviation's share of the greenhouse gas emissions is poised to grow, as air travel increases and ground vehicles use more alternative fuels like ethanol and biodiesel.\n",
      "\tBoeing estimates that biofuels could reduce flight-related greenhouse-gas emissions by 60 to 80%.\n",
      "\tIn November 2017, a statement by 15,364 scientists from 184 countries indicated that increasing levels of greenhouse gases from use of fossil fuels, human population growth, deforestation, and overuse of land for agricultural production, particularly by farming ruminants for meat consumption, are trending in ways that forecast an increase in human misery over coming decades.\n",
      "\n",
      "Top-5 Hard negatives: \n",
      "\tIt is thought that this will reduce aviation's net environmental impact.\n",
      "\tIn addition to the CO released by most aircraft in flight through the burning of fuels such as Jet-A (turbine aircraft) or Avgas (piston aircraft), the aviation industry contributes greenhouse gas emissions from ground airport vehicles and those used by passengers and staff to access airports, as well as through emissions generated by the production of energy used in airport buildings, the manufacture of aircraft and the construction of airport infrastructure.\n",
      "\tA 2014 life-cycle assessment of the cradle-to-grave reduction in CO by a carbon-fiber-reinforced polymer (CFRP) airliner such as a Boeing 787—including its manufacture, operations and eventual disposal—has shown that by 2050 such aircraft could reduce the airline industry's CO emissions by 14–15 percent, compared use of conventional airliners.\n",
      "\tMoreover, if other industries achieve significant cuts in their own greenhouse gas emissions, aviation's share as a proportion of the remaining emissions could also rise.\n",
      "\tThis would lead to a significant reduction in high-altitude contrails for a marginal trade-off of increased flight time and an estimated 4 percent increase in CO emissions.\n",
      "\tAbout 60 percent of aviation emissions arise from international flights, and these flights are not covered by the Kyoto Protocol and its emissions reduction targets.\n",
      "\tThe central case estimate is that aviation's contribution could grow to five percent of the total contribution by 2050 if action is not taken to tackle these emissions, though the highest scenario is 15 percent.\n",
      "\tWithin the categories of flights above, emissions from scheduled jet flights are substantially higher than turboprop or chartered jet flights.\n",
      "\tGreenpeace's chief scientist Doug Parr said that the flight was \"high-altitude greenwash\" and that producing organic oils to make biofuel could lead to deforestation and a large increase in greenhouse gas emissions.\n",
      "\tA December 2015 report finds that aircraft could generate of carbon pollution through to 2050, consuming almost 5 percent of the remaining global climate budget.\n"
     ]
    }
   ],
   "source": [
    "# show some examples of the hard negatives\n",
    "claim_id = random.choice(list(train_hard_negatives.keys()))\n",
    "print(\"Claim:\", train_data[claim_id][\"claim_text\"])\n",
    "print(f\"\\nGold evidence: \")\n",
    "for evidence in train_data[claim_id][\"evidences\"]:\n",
    "    print(f\"\\t{document_store[evidence]}\")\n",
    "print(f\"\\nTop-5 Hard negatives: \")\n",
    "for passage_id in train_hard_negatives[claim_id][:10]:\n",
    "    print(f\"\\t{document_store[passage_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
