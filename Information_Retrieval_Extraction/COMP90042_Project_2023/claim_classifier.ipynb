{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Claim Label Classification\n",
    "\n",
    "Recall that the goal of this project is to design and implement a system that takes a given `claim` and then retrieves (one or more) `evidence passages` from a document store, then using these evidence passages classifies the claim as one of these four labels: `[SUPPORTS, REFUTES, NOT_ENOUGH_INFO, DISPUTED]. \n",
    "\n",
    "Our first step will be to use train a simple BERT based clasifier which takes as input a sequence containing a `(claim, single evidence passage)` pair in the format: `[CLS] claim text [SEP] evidence text [SEP]`and classifies it by passing the `[CLS]` output embedding to a softmax classifier. If for a given claim `c`, if we have multiple evidence passages `[e_1, e_2, .., e_n]`, then we will have separate input pairs `(c, e_1)`, .., `(c, e_n)` all of which are assigned the same label. Then during inference time, given that we have multiple evidence passages and a claim, we classify every pair `(c,e_i)` and take a majority vote of the label. Note that this model assumes that the multiple evidences passages for a single claim independently determine the class label, which may not be true in some cases where the different evidences can interact in some complex way to determine the label. \n",
    "\n",
    "The next step will be to aggregate all the evidence passgaes into a single passage and classify input sequence containing `(claim, aggregated evidence passages)`. The simplest form of aggregation would be to directly concatenate all the input evidence passages into a single passage. Howevere, due to the maximum input sequence length imposed by BERT, we may need to do some truncation of these passages. This model will be able to learn the interactions between the different evidence passages which may lead to improved performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtanzids\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel, DistilBertTokenizerFast\n",
    "from tqdm import tqdm\n",
    "import random, psutil, os\n",
    "from DPR_biencoder_simple import *\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "wandb.login()\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of evidence passages: 1208827\n",
      "Number of training instances: 1228\n",
      "Number of validation instances: 154\n",
      "Number of evidence passages remaining after cleaning: 1204715\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# first let's load the data and look at some examples and the label distribution\n",
    "label_dict = {'SUPPORTS':0, 'REFUTES':1, 'NOT_ENOUGH_INFO':2, 'DISPUTED':3}\n",
    "document_store, train_data, val_data = load_data(clean=True, clean_threshold=30)\n",
    "train_labels = [label_dict[claim['claim_label']] for claim_id, claim in train_data.items()]\n",
    "val_labels = [label_dict[claim['claim_label']] for claim_id, claim in val_data.items()]\n",
    "\n",
    "# plot label distribution bar chart\n",
    "label_counts = [train_labels.count(i) for i in range(4)]\n",
    "labels = ['SUPPORTS', 'REFUTES', 'NOT_ENOUGH_INFO', 'DISPUTED']\n",
    "\n",
    "plt.bar(labels, label_counts)\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Training Label Distribution')\n",
    "plt.show()\n",
    "\n",
    "label_counts = [val_labels.count(i) for i in range(4)]\n",
    "plt.bar(labels, label_counts)\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Validation Label Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution is slightly imbalanced, with much fewer instances for labels REFUTES and DISPUTED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "claim-2255 --> And  since the last ice age ended almost exactly 11,500 years ago\" (Ice Age Now)\n",
      "Evidences:\n",
      "\tThe last continental glaciation ended 10,000years ago.\n",
      "\tThe last cold episode of the last glacial period ended about 10,000 years ago.\n",
      "\tDuring the most recent North American glaciation, during the latter part of the Last Glacial Maximum (26,000 to 13,300 years ago), ice sheets extended to about 45th parallel north.\n",
      "\tAccordingly, at glacial times the humid climatic belt that today is situated several latitude degrees further to the S, was shifted much further to the N. Although the last glacial period ended more than 8,000 years ago, its effects can still be felt today.\n",
      "\tThe earth is currently in an interglacial, and the last glacial period ended about 10,000 years ago.\n",
      "Claim Label: NOT_ENOUGH_INFO\n",
      "\n",
      "claim-1798 --> A few degrees of global warming has a huge impact on ice sheets, sea levels and other aspects of climate.\n",
      "Evidences:\n",
      "\tThe rate of ice loss from glaciers and ice sheets in the Antarctic is a key area of uncertainty since this source could account for 90% of the potential sea level rise: increased ocean warmth is undermining and threatening to unplug Antarctic glacier outlets, potentially resulting in more rapid sea level rise.\n",
      "\tThe effects of global warming include rising sea levels, regional changes in precipitation, more frequent extreme weather events such as heat waves, and expansion of deserts.\n",
      "\tUnder the influence of global warming, melt at the base of the ice sheet increases.\n",
      "Claim Label: SUPPORTS\n",
      "\n",
      "claim-2170 --> Climate change isn't increasing extreme weather damage costs\n",
      "Evidences:\n",
      "\tFor example, developed countries will be negatively affected by increases in the severity and frequency of some extreme weather events, such as heat waves.\n",
      "\tGlobal losses reveal rapidly rising costs due to extreme weather-related events since the 1970s.\n",
      "\tFor example, humans living on atoll islands face risks due to sea level rise, sea surface warming, and increased frequency and intensity of extreme weather events.\n",
      "\tGlobal warming boosts the probability of extreme weather events, like heat waves, far more than it boosts more moderate events.\n",
      "Claim Label: REFUTES\n",
      "\n",
      "claim-591 --> But it is part of a long list of studies from independent teams (as this interactive graphic shows), using a variety of methods that take account of critical challenges, all of which conclude that climate models exhibit too much sensitivity to greenhouse gases.\n",
      "Evidences:\n",
      "\tA 2007 study by David Douglass and coworkers, concluded that the 22 most commonly used global climate models used by the IPCC were unable to accurately predict accelerated warming in the troposphere although they did match actual surface warming, concluding \"projections of future climate based on these models should be viewed with much caution\".\n",
      "\tOver several decades of development, models have consistently provided a robust and unambiguous picture of significant climate warming in response to increasing greenhouse gases.\n",
      "Claim Label: DISPUTED\n",
      "\n",
      "claim-311 --> there has been no systematic increase in the frequency of extreme weather events,\n",
      "Evidences:\n",
      "\tThese changes have impacted river flow, increased the frequency of extreme weather events, and led to the retreat of glaciers.\n",
      "\tThis has led to an increase in the number and severity of extreme weather events.\n",
      "Claim Label: REFUTES\n",
      "\n",
      "claim-2262 --> Since the hockey stick paper in 1998, there have been a number of proxy studies analysing a variety of different sources including corals, stalagmites, tree rings, boreholes and ice cores.\n",
      "Evidences:\n",
      "\tFor his postdoctoral research, Mann joined Bradley and tree ring specialist Malcolm K. Hughes to develop a new statistical approach to reconstruct underlying spatial patterns of temperature variation combining diverse datasets of proxy information covering different periods across the globe, including a rich resource of tree ring networks for some areas and sparser proxies such as lake sediments, ice cores and corals, as well as some historical records.\n",
      "\tPaleoclimatology uses a variety of proxy methods from the Earth and life sciences to obtain data previously preserved within rocks, sediments, boreholes, ice sheets, tree rings, corals, shells, and microfossils.\n",
      "\tExamples of proxies include ice cores, tree rings, sub-fossil pollen, boreholes, corals, lake and ocean sediments, and carbonate speleothems.\n",
      "\tSeveral studies, including and have compiled box and gravity cores in the North Pacific analyzing them for palynological content to determine the distribution of dinocysts and their relationships with sea surface temperature, salinity, productivity and upwelling.\n",
      "Claim Label: SUPPORTS\n",
      "\n",
      "claim-1452 --> Most of the warming occurred in the past 35 years, with the five warmest years on record taking place since 2010.\n",
      "Evidences:\n",
      "\tThis decade is on track to become the warmest since records began in 1850, and 2009 could rank among the top-five warmest years, the U.N. weather agency reported Tuesday on the second day of a pivotal 192-nation climate conference.\n",
      "\tIn December 2009, the World Meteorological Organization (WMO) announced that the 2000s may have been the warmest decade since records began in 1850, with four of the five warmest years since 1850 having occurred in this decade.\n",
      "\tThe temperature was the hottest measured in 68 years.\n",
      "\tMultiple independently produced instrumental datasets confirm that the 20092018 decade was 0.93  0.07C warmer than the pre-industrial baseline (18501900).\n",
      "\tThe period from 1983 to 2012 was likely the warmest 30-year period of the last 1400 years in the Northern Hemisphere, where such assessment is possible (medium confidence).\n",
      "Claim Label: NOT_ENOUGH_INFO\n",
      "\n",
      "claim-10 --> Human additions of CO2 are in the margin of error of current measurements and the gradual increase in CO2 is mainly from oceans degassing as the planet slowly emerges from the last ice age.\n",
      "Evidences:\n",
      "\tMore recently, anthropogenic activities have steadily increased the carbon dioxide content of the atmosphere; about 3040% of the added CO2 is absorbed by the oceans, forming carbonic acid and lowering the pH (now below 8.1) through a process called ocean acidification.\n",
      "Claim Label: REFUTES\n",
      "\n",
      "claim-418 --> describes a world of worsening food shortages and wildfires, and a mass die-off of coral reefs as soon as 2040\n",
      "Evidences:\n",
      "\tDuring this period, 19 percent of coral reefs worldwide were lost, and 60 percent of the remaining reefs are at immediate risk of being lost.\n",
      "\tMalnutrition, dehydration and related diseases Mass migration, resulting in internal displacement and international refugees Reduced electricity production due to reduced water-flow through hydroelectric dams Shortages of water for industrial users Snake migration, which results in snake-bites Social unrest War over natural resources, including water and food Wildfires, such as Australian bushfires, become more common during times of drought and may cause human deaths.\n",
      "\tWith degradation of protective coral reefs through acidic erosion, bleaching and death, salt water is able to infiltrate fresh ground water supplies that large populations depend on.\n",
      "\tBattle for the Reef  Four Corners  ABC.au Great Barrier Reef scientists confirm largest die-off of corals recorded.\n",
      "\tA recent paper published by the National Academy of Sciences of the USA warns that: \"Synergistic effects of habitat destruction, overfishing, introduced species, warming, acidification, toxins, and massive runoff of nutrients are transforming once complex ecosystems like coral reefs and kelp forests into monotonous level bottoms, transforming clear and productive coastal seas into anoxic dead zones, and transforming complex food webs topped by big animals into simplified, microbially dominated ecosystems with boom and bust cycles of toxic dinoflagellate blooms, jellyfish, and disease\".\n",
      "Claim Label: SUPPORTS\n",
      "\n",
      "claim-196 --> Without carbon dioxide, all life on Earth would die\n",
      "Evidences:\n",
      "\tCarbon dioxide in the Earth's atmosphere is essential to life and to most of the planetary biosphere.\n",
      "Claim Label: SUPPORTS\n"
     ]
    }
   ],
   "source": [
    "# show some examples of claims, evidence, and labels\n",
    "c = random.sample(list(train_data.items()), 10)\n",
    "for claim_id, claim in c:\n",
    "    print(f\"\\n{claim_id} --> {claim['claim_text']}\")\n",
    "    print(f\"Evidences:\")\n",
    "    for ev in claim['evidences']:\n",
    "        print(f\"\\t{document_store[ev]}\")\n",
    "    print(f\"Claim Label: {claim['claim_label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The DISPUTED label is typically assigned when when the evidences contain conflicting ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set tokenizer parallelism to False\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  \n",
    "\n",
    "# single evidence dataset\n",
    "class ClaimsDatasetSingle(Dataset):\n",
    "    def __init__(self, claims_data, document_store, label_dict, block_size=192):\n",
    "        self.claims_data = claims_data\n",
    "        self.document_store = document_store\n",
    "        self.label_dict = label_dict\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.block_size = block_size\n",
    "        self.claim_pairs = self.create_pairs()\n",
    "\n",
    "    def create_pairs(self):\n",
    "        claim_pairs = []\n",
    "        for claim_id in self.claims_data.keys():\n",
    "            for evidence_id in self.claims_data[claim_id]['evidences']:\n",
    "                claim_pairs.append((claim_id, evidence_id))  \n",
    "        return claim_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.claim_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get claim id and evidence id\n",
    "        claim_id, evidence_id = self.claim_pairs[idx]\n",
    "        target_label = self.label_dict[self.claims_data[claim_id]['claim_label']]\n",
    "        # get the claim and evidence text\n",
    "        claim_text = self.claims_data[claim_id]['claim_text']\n",
    "        evidence_text = self.document_store[evidence_id]\n",
    "        # encode and create tensors\n",
    "        input_idx, input_attn_mask, token_type_idx = self.tokenize_and_encode(claim_text, evidence_text)\n",
    "        target_label = torch.tensor(target_label)\n",
    "        return input_idx, input_attn_mask, token_type_idx, target_label\n",
    "\n",
    "    def tokenize_and_encode(self, claim_text, evidence_text):\n",
    "        # tokenize the claim and evidence text  \n",
    "        claim_encoding = self.tokenizer.encode_plus(claim_text, add_special_tokens=False, return_offsets_mapping=False, return_attention_mask=False, return_token_type_ids=False)\n",
    "        claim_idx = claim_encoding['input_ids']\n",
    "        evidence_encoding = self.tokenizer.encode_plus(evidence_text, add_special_tokens=False, return_offsets_mapping=False, return_attention_mask=False, return_token_type_ids=False)\n",
    "        evidence_idx = evidence_encoding['input_ids']\n",
    "\n",
    "        # select a random window from the evidence passage if it won't fit in block size\n",
    "        max_evidence_size = self.block_size - len(claim_idx) - 3\n",
    "        if len(evidence_idx) > max_evidence_size:\n",
    "            # pick a random start position\n",
    "            start_pos = random.randint(0, max(0,len(evidence_idx)-max_evidence_size))\n",
    "            # select the window\n",
    "            evidence_idx = evidence_idx[start_pos:start_pos+max_evidence_size]\n",
    " \n",
    "        # concatenate the claim and evidence, add special tokens and padding\n",
    "        input_idx = [self.tokenizer.cls_token_id] + claim_idx + [self.tokenizer.sep_token_id] + evidence_idx + [self.tokenizer.sep_token_id]\n",
    "        input_idx = input_idx + [self.tokenizer.pad_token_id] * (self.block_size - len(input_idx))    \n",
    "\n",
    "        # create segment ids\n",
    "        claim_len = len(claim_idx) + 2\n",
    "        evidence_len = len(evidence_idx) + 1\n",
    "        token_type_idx = [0] * claim_len + [1] * evidence_len + [0] * (self.block_size - claim_len - evidence_len)\n",
    "\n",
    "        # make sure the passage sequences and claim sequences are not longer than max_length\n",
    "        if len(input_idx) > self.block_size:\n",
    "            raise Exception(f\"Input sequence length {len(input_idx)} is longer than max_length {self.block_size}!\")\n",
    "    \n",
    "        # create attention masks\n",
    "        input_attn_mask = [1 if idx != self.tokenizer.pad_token_id else 0 for idx in input_idx]\n",
    "        # convert to tensors\n",
    "        input_idx = torch.tensor(input_idx)\n",
    "        input_attn_mask = torch.tensor(input_attn_mask)\n",
    "        token_type_idx = torch.tensor(token_type_idx)  # don't need this for roberta\n",
    "\n",
    "        return input_idx, input_attn_mask, token_type_idx\n",
    "\n",
    "\n",
    "# aggregated evidences dataset\n",
    "class ClaimsDatasetAggregate(Dataset):\n",
    "    def __init__(self, claims_data, document_store, label_dict, block_size=192):\n",
    "        self.claims_data = list(claims_data.items())\n",
    "        self.document_store = document_store\n",
    "        self.label_dict = label_dict\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.claims_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get claim and evidence texts\n",
    "        claim_id, claim = self.claims_data[idx]\n",
    "        claim_text = claim['claim_text']\n",
    "        evidences_text = [self.document_store[evidence_id] for evidence_id in claim['evidences']]\n",
    "        target_label = self.label_dict[claim['claim_label']]\n",
    "        # encode and create tensors\n",
    "        input_idx, input_attn_mask, token_type_idx = self.tokenize_and_encode(claim_text, evidences_text)\n",
    "        target_label = torch.tensor(target_label)\n",
    "        return input_idx, input_attn_mask, token_type_idx, target_label\n",
    "\n",
    "    def tokenize_and_encode(self, claim_text, evidences_text):\n",
    "        # tokenize the claim and evidence text  \n",
    "        claim_encoding = self.tokenizer.encode_plus(claim_text, add_special_tokens=False, return_offsets_mapping=False, return_attention_mask=False, return_token_type_ids=False)\n",
    "        claim_idx = claim_encoding['input_ids']\n",
    "        evidence_encoding = self.tokenizer.batch_encode_plus(evidences_text, add_special_tokens=False, return_offsets_mapping=False, return_attention_mask=False, return_token_type_ids=False)\n",
    "        evidence_idx = evidence_encoding['input_ids']\n",
    "\n",
    "        # take a separate random window from each evidence passage, make sure the window proportions are the same, and that it fits in max_evidence_size\n",
    "        total_evidence_length = sum([len(evidence) for evidence in evidence_idx])\n",
    "        max_evidence_size = self.block_size - len(claim_idx) - 3\n",
    "        if total_evidence_length > max_evidence_size:\n",
    "            windowed_evidence_idx = []\n",
    "            for evidence in evidence_idx:\n",
    "                desired_length = max_evidence_size*len(evidence)//total_evidence_length\n",
    "                # pick a random start position\n",
    "                start_pos = random.randint(0, max(0,len(evidence)-desired_length))\n",
    "                # select the window\n",
    "                evidence = evidence[start_pos:start_pos+desired_length]\n",
    "                windowed_evidence_idx.append(evidence)\n",
    "            evidence_idx = windowed_evidence_idx\n",
    "\n",
    "        # concatenate the evidences\n",
    "        evidence_idx = [idx for evidence in evidence_idx for idx in evidence] \n",
    "                  \n",
    "        # concatenate the claim and evidence, add special tokens and padding\n",
    "        input_idx = [self.tokenizer.cls_token_id] + claim_idx + [self.tokenizer.sep_token_id] + evidence_idx + [self.tokenizer.sep_token_id]\n",
    "        input_idx = input_idx + [self.tokenizer.pad_token_id] * (self.block_size - len(input_idx))    \n",
    "\n",
    "        # create segment ids\n",
    "        claim_len = len(claim_idx) + 2\n",
    "        evidence_len = len(evidence_idx) + 1\n",
    "        token_type_idx = [0] * claim_len + [1] * evidence_len + [0] * (self.block_size - claim_len - evidence_len)\n",
    "\n",
    "        # make sure the passage sequences and claim sequences are not longer than max_length\n",
    "        if len(input_idx) > self.block_size:\n",
    "            raise Exception(f\"Input sequence length {len(input_idx)} is longer than max_length {self.block_size}!\")\n",
    "    \n",
    "        # create attention masks\n",
    "        input_attn_mask = [1 if idx != self.tokenizer.pad_token_id else 0 for idx in input_idx]\n",
    "        # convert to tensors\n",
    "        input_idx = torch.tensor(input_idx)\n",
    "        input_attn_mask = torch.tensor(input_attn_mask)\n",
    "        token_type_idx = torch.tensor(token_type_idx)  # don't need this for roberta\n",
    "\n",
    "        return input_idx, input_attn_mask, token_type_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClaimClassifier(torch.nn.Module):\n",
    "    def __init__(self, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        # load pretrained BERT model\n",
    "        self.bert_encoder = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        # define classifier head\n",
    "        self.classifier_head = torch.nn.Linear(768, 4)\n",
    "        # make sure BERT parameters are trainable\n",
    "        for param in self.bert_encoder.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, input_idx, input_attn_mask, token_type_idx, targets=None):\n",
    "        # compute BERT encodings, extract the pooler output (which is just the [CLS] embedding fed through a feedforward network or just the [CLS] embedding), apply dropout        \n",
    "        bert_output = self.bert_encoder(input_idx, attention_mask=input_attn_mask, token_type_ids=token_type_idx)\n",
    "        pooled_output = self.dropout(bert_output.last_hidden_state[:,0]) # shape: (batch_size, hidden_size)\n",
    "        # compute output logits\n",
    "        logits = self.classifier_head(pooled_output) # shape: (batch_size, 4)\n",
    "        # compute cross-entropy loss\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "\n",
    "# training loop\n",
    "def train(model, optimizer, train_dataloader, val_dataloader, scheduler=None, device=\"cpu\", num_epochs=10, accumulation_steps=1, val_every=100, save_every=None, log_metrics=None):\n",
    "    avg_loss = 0\n",
    "    train_acc = 0\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    model.train()\n",
    "    # reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    for epoch in range(num_epochs):\n",
    "        num_correct = 0\n",
    "        num_total = 0\n",
    "        pbar = tqdm(train_dataloader, desc=\"Epochs\")\n",
    "        for i, batch in enumerate(pbar):\n",
    "            input_idx, input_attn_mask, token_type_idx, targets = batch\n",
    "            # move batch to device\n",
    "            input_idx, input_attn_mask, token_type_idx, targets = input_idx.to(device), input_attn_mask.to(device), token_type_idx.to(device), targets.to(device)\n",
    "            # forward pass\n",
    "            logits, loss = model(input_idx, input_attn_mask, token_type_idx, targets)\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            # apply gradient step \n",
    "            if (i+1) % accumulation_steps == 0:\n",
    "                # optimizer step\n",
    "                optimizer.step()\n",
    "                # reset gradients\n",
    "                optimizer.zero_grad()\n",
    "   \n",
    "            avg_loss = 0.9* avg_loss + 0.1*loss.item()\n",
    "            B, _ = input_idx.shape\n",
    "            y_pred = logits.argmax(dim=-1).view(-1) # shape (B,)\n",
    "            num_correct += (y_pred.eq(targets.view(-1))).sum().item()      \n",
    "            num_total += B\n",
    "            train_acc = num_correct / num_total        \n",
    "\n",
    "            if val_every is not None:\n",
    "                if i%val_every == 0:\n",
    "                    # compute validation loss\n",
    "                    val_loss, val_acc = validation(model, val_dataloader, device=device)\n",
    "                    pbar.set_description(f\"Epoch {epoch + 1}, EMA Train Loss: {avg_loss:.3f}, Train Accuracy: {train_acc: .3f}, Val Loss: {val_loss: .3f}, Val Accuracy: {val_acc: .3f}\")  \n",
    "\n",
    "            pbar.set_description(f\"Epoch {epoch + 1}, EMA Train Loss: {avg_loss:.3f}, Train Accuracy: {train_acc: .3f}, Val Loss: {val_loss: .3f}, Val Accuracy: {val_acc: .3f}\")  \n",
    "\n",
    "            if log_metrics:\n",
    "                metrics = {\"Batch loss\":loss.item(), \"Moving Avg Loss\":avg_loss, \"Train Accuracy\":train_acc, \"Val Loss\": val_loss, \"Val Accuracy\":val_acc}\n",
    "                log_metrics(metrics)\n",
    "\n",
    "        # run optimizer step for remainder batches\n",
    "        if len(train_dataloader) % accumulation_steps != 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        if save_every is not None:\n",
    "            if (epoch+1) % save_every == 0:\n",
    "                save_model_checkpoint(model, optimizer, epoch, avg_loss)\n",
    "\n",
    "\n",
    "def validation(model, val_dataloader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    val_losses = torch.zeros(len(val_dataloader))\n",
    "    with torch.no_grad():\n",
    "        num_correct = 0\n",
    "        num_total = 0\n",
    "        for i,batch in enumerate(val_dataloader):\n",
    "            input_idx, input_attn_mask, token_type_idx, targets = batch\n",
    "            input_idx, input_attn_mask, token_type_idx, targets = input_idx.to(device), input_attn_mask.to(device), token_type_idx.to(device), targets.to(device)\n",
    "            logits, loss = model(input_idx, input_attn_mask, token_type_idx, targets)\n",
    "            B, _ = input_idx.shape\n",
    "            y_pred = logits.argmax(dim=-1).view(-1) # shape (B,)\n",
    "            num_correct += (y_pred.eq(targets.view(-1))).sum().item()      \n",
    "            num_total += B\n",
    "            val_losses[i] = loss.item()\n",
    "    model.train()\n",
    "    val_loss = val_losses.mean().item()\n",
    "    val_accuracy = num_correct / num_total\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "def save_model_checkpoint(model, optimizer, epoch=None, loss=None, filename=None):\n",
    "    # Save the model and optimizer state_dict\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }\n",
    "    # Save the checkpoint to a file\n",
    "    if filename:\n",
    "        torch.save(checkpoint, filename)\n",
    "    else:\n",
    "        torch.save(checkpoint, 'classifier_checkpoint.pth')\n",
    "    print(f\"Saved model checkpoint!\")\n",
    "\n",
    "\n",
    "\n",
    "def load_model_checkpoint(model, optimizer=None, filename=None):\n",
    "    if filename:\n",
    "        checkpoint = torch.load(filename)\n",
    "    else:\n",
    "        checkpoint = torch.load('classifier_checkpoint.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(\"Loaded model from checkpoint!\")\n",
    "    if optimizer:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        model.train()\n",
    "        return model, optimizer          \n",
    "    else:\n",
    "        return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we will train the model using the single evidence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4122 491\n"
     ]
    }
   ],
   "source": [
    "block_size = 256\n",
    "train_dataset = ClaimsDatasetSingle(train_data, document_store, label_dict, block_size=block_size)\n",
    "val_dataset = ClaimsDatasetSingle(val_data, document_store, label_dict, block_size=block_size)\n",
    "print(len(train_dataset), len(val_dataset)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from checkpoint!\n",
      "Total number of parameters in transformer network: 109.485316 M\n",
      "RAM used: 3609.84 MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "B = 16\n",
    "DEVICE = \"cuda\"\n",
    "learning_rate = 1e-5\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=B, shuffle=True, pin_memory=True, num_workers=2)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=B, shuffle=True, pin_memory=True, num_workers=2)\n",
    "\n",
    "# model with finetuning disabled\n",
    "model = ClaimClassifier(dropout_rate=0.1).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler =  torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.95)\n",
    "model, optimizer = load_model_checkpoint(model, optimizer)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters in transformer network: {num_params/1e6} M\")\n",
    "print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tanzid/Code/NLP/Information_Retrieval_Extraction/COMP90042_Project_2023/wandb/run-20240123_215759-d9u9qr5b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tanzids/Automated%20Climate%20Fact%20Checker/runs/d9u9qr5b' target=\"_blank\">sleek-galaxy-44</a></strong> to <a href='https://wandb.ai/tanzids/Automated%20Climate%20Fact%20Checker' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tanzids/Automated%20Climate%20Fact%20Checker' target=\"_blank\">https://wandb.ai/tanzids/Automated%20Climate%20Fact%20Checker</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tanzids/Automated%20Climate%20Fact%20Checker/runs/d9u9qr5b' target=\"_blank\">https://wandb.ai/tanzids/Automated%20Climate%20Fact%20Checker/runs/d9u9qr5b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project=\"Automated Climate Fact Checker\", \n",
    "    config={\n",
    "        \"bi-encoder model\": \"BERT\",\n",
    "        \"learning_rate\": learning_rate, \n",
    "        \"epochs\": 5,\n",
    "        \"batch_size\": B, \n",
    "        \"corpus\": \"COMP90042 2023 project\"},)   \n",
    "\n",
    "def log_metrics(metrics):\n",
    "    wandb.log(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, EMA Train Loss: 0.263, Train Accuracy:  0.889, Val Loss:  1.586, Val Accuracy:  0.525: 100%|| 258/258 [01:45<00:00,  2.44it/s]\n",
      "Epoch 2, EMA Train Loss: 0.162, Train Accuracy:  0.955, Val Loss:  1.559, Val Accuracy:  0.552: 100%|| 258/258 [01:45<00:00,  2.44it/s]\n"
     ]
    }
   ],
   "source": [
    "#train(model, optimizer, train_dataloader, val_dataloader, device=DEVICE, num_epochs=2, save_every=None, val_every=100, log_metrics=log_metrics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/154 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 154/154 [00:04<00:00, 37.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with majority voting: 0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# now lets recompute the validation accuracy, this time using majority voting over all evidence pairs per claim\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    for claim_id, claim in tqdm(val_data.items()):\n",
    "        claim_text = claim['claim_text']\n",
    "        evidences = [document_store[evidence_id] for evidence_id in claim['evidences']]\n",
    "        label = label_dict[claim['claim_label']]\n",
    "        input_idx_batch = []\n",
    "        input_attn_mask_batch = []\n",
    "        token_type_idx_batch = []\n",
    "        for evidence_text in evidences:\n",
    "            # encode and create tensors\n",
    "            input_idx, input_attn_mask, token_type_idx = val_dataset.tokenize_and_encode(claim_text, evidence_text)\n",
    "            input_idx_batch.append(input_idx)\n",
    "            input_attn_mask_batch.append(input_attn_mask)\n",
    "            token_type_idx_batch.append(token_type_idx)\n",
    "        input_idx_batch = torch.stack(input_idx_batch).to(DEVICE)\n",
    "        input_attn_mask_batch = torch.stack(input_attn_mask_batch).to(DEVICE)\n",
    "        token_type_idx_batch = torch.stack(token_type_idx_batch).to(DEVICE)\n",
    "        logits, loss = model(input_idx_batch, input_attn_mask_batch, token_type_idx_batch)\n",
    "        y_pred = logits.argmax(dim=-1).view(-1) # shape (num_evidences,)\n",
    "        # get majority label\n",
    "        y_pred = y_pred.mode().values.item()\n",
    "        num_correct += int(y_pred == label)\n",
    "        num_total += 1\n",
    "\n",
    "model.train()\n",
    "val_accuracy = num_correct / num_total\n",
    "print(f\"Validation accuracy with majority voting: {val_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The classification accuracy on the validation dataset using single evidence input and majority voting is about 54%. Now let's train the model with the aggregated evidence input, we will also increase the block_size of our input sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1228 154\n"
     ]
    }
   ],
   "source": [
    "block_size = 384\n",
    "train_dataset = ClaimsDatasetAggregate(train_data, document_store, label_dict, block_size=block_size)\n",
    "val_dataset = ClaimsDatasetAggregate(val_data, document_store, label_dict, block_size=block_size)\n",
    "print(len(train_dataset), len(val_dataset)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from checkpoint!\n",
      "Total number of parameters in transformer network: 109.485316 M\n",
      "RAM used: 3596.15 MB\n"
     ]
    }
   ],
   "source": [
    "B = 16\n",
    "DEVICE = \"cuda\"\n",
    "learning_rate = 1e-5\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=B, shuffle=True, pin_memory=True, num_workers=2)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=B, shuffle=True, pin_memory=True, num_workers=2)\n",
    "\n",
    "# model with finetuning disabled\n",
    "model = ClaimClassifier(dropout_rate=0.1).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler =  torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.95)\n",
    "model, optimizer = load_model_checkpoint(model, optimizer)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters in transformer network: {num_params/1e6} M\")\n",
    "print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tanzid/Code/NLP/Information_Retrieval_Extraction/COMP90042_Project_2023/wandb/run-20240123_222750-f9zxwdoj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tanzids/Automated%20Climate%20Fact%20Checker/runs/f9zxwdoj' target=\"_blank\">major-darkness-47</a></strong> to <a href='https://wandb.ai/tanzids/Automated%20Climate%20Fact%20Checker' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tanzids/Automated%20Climate%20Fact%20Checker' target=\"_blank\">https://wandb.ai/tanzids/Automated%20Climate%20Fact%20Checker</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tanzids/Automated%20Climate%20Fact%20Checker/runs/f9zxwdoj' target=\"_blank\">https://wandb.ai/tanzids/Automated%20Climate%20Fact%20Checker/runs/f9zxwdoj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project=\"Automated Climate Fact Checker\", \n",
    "    config={\n",
    "        \"bi-encoder model\": \"BERT\",\n",
    "        \"learning_rate\": learning_rate, \n",
    "        \"epochs\": 5,\n",
    "        \"batch_size\": B, \n",
    "        \"corpus\": \"COMP90042 2023 project\"},)   \n",
    "\n",
    "def log_metrics(metrics):\n",
    "    wandb.log(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/77 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, EMA Train Loss: 0.261, Train Accuracy:  0.906, Val Loss:  1.168, Val Accuracy:  0.636: 100%|| 77/77 [06:24<00:00,  4.99s/it]\n"
     ]
    }
   ],
   "source": [
    "#train(model, optimizer, train_dataloader, val_dataloader, device=DEVICE, num_epochs=1, save_every=None, val_every=20, log_metrics=log_metrics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model checkpoint!\n"
     ]
    }
   ],
   "source": [
    "#save_model_checkpoint(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0054893493652344, 0.6623376623376623)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(model, val_dataloader, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As expected, we see improved performance when using aggregated evidences in the input, we get over 10% increase in accuracy on the validation set. \n",
    "\n",
    "#### The next step is to create a pipeline connecting the passage retriever with the claim classifier. Instead of using the ground truth evidences for each claim from the validation set, we will draw evidences from the precomputed DPR topk and cross-encoder reranked topk to create a new evidence list based on our retreiver. Then we will classify the claims and see how that affects the classification accuracy compared to when we used the ground truth evidence list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load DPR topk\n",
    "with open(\"dpr_embeddings/val_dpr_evidences.pkl\", \"rb\") as f:\n",
    "    val_dpr_evidences_top500 = pickle.load(f)\n",
    "\n",
    "# load reranked topk\n",
    "with open(\"dpr_embeddings/val_top200_reranked.pkl\", \"rb\") as f:\n",
    "    val_top200_reranked = pickle.load(f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the retreived evidence list, we will start out by using the top-3 reranked evidences and the top-3 from the DPR evidences. We could choose any number of different combinations, but for simplicity, we choose this particular one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/154 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 154/154 [00:02<00:00, 61.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with retreived evidences: 0.416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reranked_topk=3\n",
    "dpr_topk=3\n",
    "\n",
    "model.eval()\n",
    "num_correct = 0\n",
    "num_total = 0\n",
    "for claim_id, claim in tqdm(val_data.items()):\n",
    "    claim_text = claim['claim_text']\n",
    "    # pick evidences from reranked and from DPR\n",
    "    evidence_ids = set(val_top200_reranked[claim_id][:reranked_topk] + val_dpr_evidences_top500[claim_id][0][:dpr_topk])\n",
    "    evidences_text = [document_store[id] for id in evidence_ids]\n",
    "    label = label_dict[claim['claim_label']]\n",
    "    # encode and create tensors\n",
    "    input_idx, input_attn_mask, token_type_idx = val_dataset.tokenize_and_encode(claim_text, evidences_text)\n",
    "    with torch.no_grad():\n",
    "        logits, loss = model(input_idx.view(1,-1).to(DEVICE), input_attn_mask.view(1,-1).to(DEVICE), token_type_idx.view(1,-1).to(DEVICE))\n",
    "    y_pred = logits.argmax(dim=-1).view(-1) \n",
    "    num_correct += int(y_pred.item() == label)\n",
    "    num_total += 1\n",
    "\n",
    "val_accuracy = num_correct / num_total\n",
    "print(f\"Validation accuracy with retreived evidences: {val_accuracy:.3f}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With top-3 from reranked and top-3 from dpr passages, we get a classification accuracy of 41%. This is substantially lower than the accuracy from using the ground truth evidence passages.\n",
    "\n",
    "We can try a few different combinations and see if we can improve on this result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/154 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 154/154 [00:02<00:00, 65.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with reranked top-2 and dpr top-0: 0.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 154/154 [00:02<00:00, 74.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with reranked top-3 and dpr top-0: 0.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 154/154 [00:02<00:00, 70.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with reranked top-4 and dpr top-0: 0.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 154/154 [00:02<00:00, 71.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with reranked top-5 and dpr top-0: 0.416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 154/154 [00:02<00:00, 71.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with reranked top-0 and dpr top-2: 0.481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 154/154 [00:02<00:00, 73.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with reranked top-0 and dpr top-3: 0.481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 154/154 [00:02<00:00, 73.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with reranked top-0 and dpr top-4: 0.435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 154/154 [00:02<00:00, 72.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with reranked top-0 and dpr top-5: 0.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 154/154 [00:02<00:00, 73.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with reranked top-1 and dpr top-1: 0.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 154/154 [00:02<00:00, 68.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with reranked top-1 and dpr top-2: 0.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 154/154 [00:02<00:00, 67.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with reranked top-1 and dpr top-3: 0.435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 154/154 [00:02<00:00, 68.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with reranked top-2 and dpr top-1: 0.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 154/154 [00:02<00:00, 69.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with reranked top-3 and dpr top-1: 0.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 154/154 [00:02<00:00, 67.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with reranked top-2 and dpr top-2: 0.416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 154/154 [00:02<00:00, 68.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with reranked top-3 and dpr top-2: 0.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 154/154 [00:02<00:00, 67.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with reranked top-2 and dpr top-3: 0.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 154/154 [00:02<00:00, 68.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with reranked top-3 and dpr top-3: 0.416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 154/154 [00:02<00:00, 67.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with reranked top-4 and dpr top-4: 0.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for reranked_topk, dpr_topk in [(2,0), (3,0), (4,0), (5,0), (0,2), (0,3), (0,4) ,(0,5), (1,1), (1,2), (1,3), (2,1), (3,1), (2,2), (3,2), (2,3), (3,3), (4,4)]:\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    for claim_id, claim in tqdm(val_data.items()):\n",
    "        claim_text = claim['claim_text']\n",
    "        # pick evidences from reranked and from DPR\n",
    "        evidence_ids = set(val_top200_reranked[claim_id][:reranked_topk] + val_dpr_evidences_top500[claim_id][0][:dpr_topk])\n",
    "        evidences_text = [document_store[id] for id in evidence_ids]\n",
    "        label = label_dict[claim['claim_label']]\n",
    "        # encode and create tensors\n",
    "        input_idx, input_attn_mask, token_type_idx = val_dataset.tokenize_and_encode(claim_text, evidences_text)\n",
    "        with torch.no_grad():\n",
    "            logits, loss = model(input_idx.view(1,-1).to(DEVICE), input_attn_mask.view(1,-1).to(DEVICE), token_type_idx.view(1,-1).to(DEVICE))\n",
    "        y_pred = logits.argmax(dim=-1).view(-1) \n",
    "        num_correct += int(y_pred.item() == label)\n",
    "        num_total += 1\n",
    "\n",
    "    val_accuracy = num_correct / num_total\n",
    "    print(f\"Validation accuracy with reranked top-{reranked_topk} and dpr top-{dpr_topk}: {val_accuracy:.3f}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the top-2 or top-3 from the DPR passages seems to give the highest accuracy (48%) on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
