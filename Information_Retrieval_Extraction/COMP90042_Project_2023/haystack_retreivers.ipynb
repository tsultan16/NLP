{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Haystack Passage Retirevers\n",
    "\n",
    "Previously we implemented our own BM25 and DPR retreiver models. We will now switch to using retreiver models provided by the Haystack library, which are optimized for better performance and have loads of useful features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores import InMemoryDocumentStore\n",
    "from haystack.nodes import BM25Retriever\n",
    "from utils import *\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of evidence passages: 1208827\n",
      "Number of training instances: 1228\n",
      "Number of validation instances: 154\n",
      "Number of evidence passages remaining after cleaning: 1204715\n"
     ]
    }
   ],
   "source": [
    "# load data from file\n",
    "passages, train_data, val_data = load_data(clean=True, clean_threshold=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating BM25 representation...: 100%|██████████| 1204715/1204715 [00:17<00:00, 69241.03 docs/s]\n"
     ]
    }
   ],
   "source": [
    "documents = [{\"id\":p_id, \"content\": p_text} for p_id, p_text in list(passages.items())]\n",
    "\n",
    "# create haystack in-memory document store\n",
    "document_store = InMemoryDocumentStore(use_bm25=True)\n",
    "document_store.write_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a haystack BM-25 retreiver\n",
    "retreiver = BM25Retriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_claims = list(train_data.items())\n",
    "val_claims = list(val_data.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out this BM25 retreiver on some example claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claim --> that atmospheric CO2 increase that we observe is a product of temperature  increase, and not the other way around, meaning it is a product of  natural variation...\n",
      "\n",
      "Gold evidences: \n",
      "\t evidence-368192 --> Increases in atmospheric concentrations of CO 2 and other long-lived greenhouse gases such as methane, nitrous oxide and ozone have correspondingly strengthened their absorption and emission of infrared radiation, causing the rise in average global temperature since the mid-20th century.\n",
      "\t evidence-423643 --> During the late 20th century, a scientific consensus evolved that increasing concentrations of greenhouse gases in the atmosphere cause a substantial rise in global temperatures and changes to other parts of the climate system, with consequences for the environment and for human health.\n",
      "\n",
      "BM25 top-5 documents:\n",
      "\tevidence-100018 --> The ice core data shows that temperature change causes the level of atmospheric CO2 to change - not the other way round.\n",
      "\tevidence-548766 --> Due to the increase in temperature of the soil, CO2 levels in our atmosphere increase, and as such the mean average temperature of the Earth is rising.\n",
      "\tevidence-498380 --> Current annual increase in atmospheric CO2 is approximately 4 gigatons of carbon.\n",
      "\tevidence-296134 --> The ice core data shows that temperature change causes the level of atmospheric to change — not the other way round.\n",
      "\tevidence-382866 --> The heat needed to raise an average temperature increase of the entire world ocean by 0.01 °C would increase the atmospheric temperature by approximately 10 °C.\n"
     ]
    }
   ],
   "source": [
    "# now do a quick test of the retriever\n",
    "idx = random.randint(0, len(train_claims))  \n",
    "claim_text = train_claims[idx][1]['claim_text']\n",
    "gold_evidence_list = train_claims[idx][1][\"evidences\"]\n",
    "\n",
    "# retreive BM25 top-5 documents  \n",
    "topk_documents = retreiver.retrieve(query=claim_text, top_k=5)\n",
    "\n",
    "print(f\"Claim --> {claim_text}\")\n",
    "print(f\"\\nGold evidences: \")\n",
    "for evidence in gold_evidence_list:\n",
    "    print(f\"\\t {evidence} --> {passages[evidence]}\")\n",
    "\n",
    "print(f\"\\nBM25 top-5 documents:\")\n",
    "for doc in topk_documents:\n",
    "    print(f\"\\t{doc.id} --> {doc.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the evaluation metrics for this BM25 retreiver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('claim-1937',\n",
       " {'claim_text': 'Not only is there no scientific evidence that CO2 is a pollutant, higher CO2 concentrations actually help ecosystems support more plant and animal life.',\n",
       "  'claim_label': 'DISPUTED',\n",
       "  'evidences': ['evidence-442946', 'evidence-1194317', 'evidence-12171']})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_claims[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(claims_list, retreiver, topk=[5]):\n",
    "    precision_total = np.zeros(len(topk))\n",
    "    recall_total = np.zeros(len(topk))\n",
    "    f1_total = np.zeros(len(topk))\n",
    "\n",
    "    for claim_id, claim in tqdm(claims_list):\n",
    "        claim_text = claim['claim_text']\n",
    "        gold_evidence_list = claim['evidences']\n",
    "        # get BM25 top-k passages \n",
    "        topk_documents = retreiver.retrieve(query=claim_text, top_k=max(topk)) \n",
    "        \n",
    "        # keep top-k reranked passages\n",
    "        for i,k in enumerate(topk):\n",
    "            retreived_doc_ids = [doc.id for doc in topk_documents[:k]]\n",
    "            intersection = set(retreived_doc_ids).intersection(gold_evidence_list)\n",
    "            precision = len(intersection) / len(retreived_doc_ids)\n",
    "            recall = len(intersection) / len(gold_evidence_list)\n",
    "            f1 = (2*precision*recall/(precision + recall)) if (precision + recall) > 0 else 0 \n",
    "            precision_total[i] += precision\n",
    "            recall_total[i] += recall\n",
    "            f1_total[i] += f1\n",
    "\n",
    "    precision_avg = precision_total / len(claims_list)\n",
    "    recall_avg = recall_total / len(claims_list)\n",
    "    f1_avg = f1_total / len(claims_list)    \n",
    "\n",
    "    # convert to dictionary\n",
    "    precision_avg = {f\"Precision@{k}\":v for k,v in zip(topk, precision_avg)}\n",
    "    recall_avg = {f\"Recall@{k}\":v for k,v in zip(topk, recall_avg)}\n",
    "    f1_avg = {f\"F1@{k}\":v for k,v in zip(topk, f1_avg)}\n",
    "\n",
    "    print(f\"\\nAvg Precision: {precision_avg}, Avg Recall: {recall_avg}, Avg F1: {f1_avg}\")\n",
    "    return precision_avg, recall_avg, f1_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/1228 [01:00<1:45:25,  5.21s/it]"
     ]
    }
   ],
   "source": [
    "# eval on training set\n",
    "print(\"Evaluating on training set...\")\n",
    "eval(train_claims, retreiver, topk=[1, 3, 5, 10, 20, 50, 100, 250, 500, 1000])\n",
    "\n",
    "print(\"Evalutating on validation set...\")\n",
    "eval(val_claims, retreiver, topk=[1, 3, 5, 10, 20, 50, 100, 250, 500, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
