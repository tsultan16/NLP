{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CKY Parsing Algorithm\n",
    "\n",
    "The `CKY` algorithm is a `dynamic programming algorithm` for efficiently creating all possible parse trees for a given sentence and context-free grammar. It requires the grammar to be in `Chomsky Normal Form (CNF)`, i.e. each production is either of the form $A \\to B C$ or $A \\to a$, where $A,B,C \\in N$ and $a \\in \\Sigma$.\n",
    "\n",
    "We will first define our grammar (borrowed from Figure 17.8, Jurafsky-Martin textbook), convert it to CNF and then implement the CKY parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grammar\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP | Aux NP VP | VP \n",
    "    NP -> Det Nom | PropN | Pronoun \n",
    "    Nom -> Noun | Nom Noun | Nom PP\n",
    "    VP -> Verb | Verb NP | Verb NP PP | Verb PP | VP PP\n",
    "    PP -> Prep NP\n",
    "    Det -> 'that' | 'this' | 'the' | 'a' \n",
    "    Noun -> 'book' | 'flight' | 'meal' | 'money'\n",
    "    Verb -> 'book' | 'include' | 'prefer'\n",
    "    Pronoun -> 'I' | 'she' | 'me'\n",
    "    PropN -> 'Houston' | 'NWA'\n",
    "    Aux -> 'does'\n",
    "    Prep -> 'from' | 'to' | 'on' | 'near' | 'through'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert this grammar to CNF, we will first binarize all the productions:\n",
    "\n",
    "`S -> Aux NP VP` becomes `S -> X1 VP` and `X1 -> Aux NP`\n",
    "\n",
    "`VP -> Verb NP PP` becomes `VP -> X2 PP` and `X2 -> Verb NP`\n",
    "\n",
    "\n",
    "Then we convert the unit production `S -> VP` into the following:\n",
    "\n",
    "S -> VP \n",
    "=> S -> Verb | Verb NP | X2 PP | Verb PP | VP PP \n",
    "=> `S -> 'book' | 'include' | 'prefer' | Verb NP | X2 PP | Verb PP | VP PP`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grammar in CNF\n",
    "grammar_CNF = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP | X1 VP | 'book' | 'include' | 'prefer' | Verb NP | X2 PP | Verb PP | VP PP \n",
    "    X1 -> Aux NP\n",
    "    NP -> Det Nom | PropN | Pronoun \n",
    "    Nom -> Noun | Nom Noun | Nom PP\n",
    "    VP -> Verb | Verb NP | X2 PP | Verb PP | VP PP\n",
    "    X2 -> Verb NP                              \n",
    "    PP -> Prep NP\n",
    "    Det -> 'that' | 'this' | 'the' | 'a' \n",
    "    Noun -> 'book' | 'flight' | 'meal' | 'money'\n",
    "    Verb -> 'book' | 'include' | 'prefer'\n",
    "    Pronoun -> 'I' | 'she' | 'me'\n",
    "    PropN -> 'Houston' | 'NWA'\n",
    "    Aux -> 'does'\n",
    "    Prep -> 'from' | 'to' | 'on' | 'near' | 'through'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S -> NP VP\n",
      "\tLHS: S\n",
      "\tRHS: (NP, VP)\n",
      "S -> X1 VP\n",
      "\tLHS: S\n",
      "\tRHS: (X1, VP)\n",
      "S -> 'book'\n",
      "\tLHS: S\n",
      "\tRHS: ('book',)\n",
      "S -> 'include'\n",
      "\tLHS: S\n",
      "\tRHS: ('include',)\n",
      "S -> 'prefer'\n",
      "\tLHS: S\n",
      "\tRHS: ('prefer',)\n",
      "S -> Verb NP\n",
      "\tLHS: S\n",
      "\tRHS: (Verb, NP)\n",
      "S -> X2 PP\n",
      "\tLHS: S\n",
      "\tRHS: (X2, PP)\n",
      "S -> Verb PP\n",
      "\tLHS: S\n",
      "\tRHS: (Verb, PP)\n",
      "S -> VP PP\n",
      "\tLHS: S\n",
      "\tRHS: (VP, PP)\n",
      "X1 -> Aux NP\n",
      "\tLHS: X1\n",
      "\tRHS: (Aux, NP)\n",
      "NP -> Det Nom\n",
      "\tLHS: NP\n",
      "\tRHS: (Det, Nom)\n",
      "NP -> PropN\n",
      "\tLHS: NP\n",
      "\tRHS: (PropN,)\n",
      "NP -> Pronoun\n",
      "\tLHS: NP\n",
      "\tRHS: (Pronoun,)\n",
      "Nom -> Noun\n",
      "\tLHS: Nom\n",
      "\tRHS: (Noun,)\n",
      "Nom -> Nom Noun\n",
      "\tLHS: Nom\n",
      "\tRHS: (Nom, Noun)\n",
      "Nom -> Nom PP\n",
      "\tLHS: Nom\n",
      "\tRHS: (Nom, PP)\n",
      "VP -> Verb\n",
      "\tLHS: VP\n",
      "\tRHS: (Verb,)\n",
      "VP -> Verb NP\n",
      "\tLHS: VP\n",
      "\tRHS: (Verb, NP)\n",
      "VP -> X2 PP\n",
      "\tLHS: VP\n",
      "\tRHS: (X2, PP)\n",
      "VP -> Verb PP\n",
      "\tLHS: VP\n",
      "\tRHS: (Verb, PP)\n",
      "VP -> VP PP\n",
      "\tLHS: VP\n",
      "\tRHS: (VP, PP)\n",
      "X2 -> Verb NP\n",
      "\tLHS: X2\n",
      "\tRHS: (Verb, NP)\n",
      "PP -> Prep NP\n",
      "\tLHS: PP\n",
      "\tRHS: (Prep, NP)\n",
      "Det -> 'that'\n",
      "\tLHS: Det\n",
      "\tRHS: ('that',)\n",
      "Det -> 'this'\n",
      "\tLHS: Det\n",
      "\tRHS: ('this',)\n",
      "Det -> 'the'\n",
      "\tLHS: Det\n",
      "\tRHS: ('the',)\n",
      "Det -> 'a'\n",
      "\tLHS: Det\n",
      "\tRHS: ('a',)\n",
      "Noun -> 'book'\n",
      "\tLHS: Noun\n",
      "\tRHS: ('book',)\n",
      "Noun -> 'flight'\n",
      "\tLHS: Noun\n",
      "\tRHS: ('flight',)\n",
      "Noun -> 'meal'\n",
      "\tLHS: Noun\n",
      "\tRHS: ('meal',)\n",
      "Noun -> 'money'\n",
      "\tLHS: Noun\n",
      "\tRHS: ('money',)\n",
      "Verb -> 'book'\n",
      "\tLHS: Verb\n",
      "\tRHS: ('book',)\n",
      "Verb -> 'include'\n",
      "\tLHS: Verb\n",
      "\tRHS: ('include',)\n",
      "Verb -> 'prefer'\n",
      "\tLHS: Verb\n",
      "\tRHS: ('prefer',)\n",
      "Pronoun -> 'I'\n",
      "\tLHS: Pronoun\n",
      "\tRHS: ('I',)\n",
      "Pronoun -> 'she'\n",
      "\tLHS: Pronoun\n",
      "\tRHS: ('she',)\n",
      "Pronoun -> 'me'\n",
      "\tLHS: Pronoun\n",
      "\tRHS: ('me',)\n",
      "PropN -> 'Houston'\n",
      "\tLHS: PropN\n",
      "\tRHS: ('Houston',)\n",
      "PropN -> 'NWA'\n",
      "\tLHS: PropN\n",
      "\tRHS: ('NWA',)\n",
      "Aux -> 'does'\n",
      "\tLHS: Aux\n",
      "\tRHS: ('does',)\n",
      "Prep -> 'from'\n",
      "\tLHS: Prep\n",
      "\tRHS: ('from',)\n",
      "Prep -> 'to'\n",
      "\tLHS: Prep\n",
      "\tRHS: ('to',)\n",
      "Prep -> 'on'\n",
      "\tLHS: Prep\n",
      "\tRHS: ('on',)\n",
      "Prep -> 'near'\n",
      "\tLHS: Prep\n",
      "\tRHS: ('near',)\n",
      "Prep -> 'through'\n",
      "\tLHS: Prep\n",
      "\tRHS: ('through',)\n",
      "Non-terminals: {Aux, Pronoun, PropN, Noun, X2, Nom, PP, Prep, NP, Det, VP, S, X1, Verb}\n",
      "Terminals: {'she', 'me', 'meal', 'include', 'does', 'near', 'that', 'flight', 'from', 'prefer', 'Houston', 'through', 'to', 'money', 'this', 'on', 'a', 'the', 'I', 'book', 'NWA'}\n"
     ]
    }
   ],
   "source": [
    "# show all the productions, terminal and non-terminal symbols\n",
    "terminals = set()\n",
    "non_terminals = set()\n",
    "for production in grammar_CNF.productions():\n",
    "    print(production)\n",
    "    print(f\"\\tLHS: {production.lhs()}\")\n",
    "    print(f\"\\tRHS: {production.rhs()}\")\n",
    "    non_terminals.add(production.lhs())\n",
    "    for symbol in production.rhs():\n",
    "        if nltk.grammar.is_terminal(symbol):\n",
    "            terminals.add(symbol)\n",
    "        else:\n",
    "            non_terminals.add(symbol)\n",
    "\n",
    "print(f\"Non-terminals: {non_terminals}\")\n",
    "print(f\"Terminals: {terminals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CKY is a dynamic programming algorithm for finding valid parse trees for a given sentence. It requires the grammar to be in CFN so that each production rule is binary. It has two steps: 1) `Recognition` and 2) `Backtracking`\n",
    "\n",
    "The `recognition` involves considering each possible span in a sentence and labelling it with an appropriate constituent from the grammar. First, we define `fenceposts` which are positions between adjacent words in the sentence. For a sentence with `n` words, position `0` is to the left of the first word and position `n` is to the right of the last word. Then we define `span [i,j]` as the words between positions `i` and `j`,  e.g. for the sentence, `0 Book 1 that 2 flight 3`, span `[1,3]` denotes `that flight`. \n",
    "\n",
    "Then for each word in the sentence (in order starting from first), we consider all spans that have right fencepost fixed at the end of that word and left fencepost which starts to the left of that word and advances one step at a time until reaching position `0`, so e.g. for the word `that`, we will first consider the span `[1,2]`, label it (since this is a single word, i.e. a terminal symbol, we assign the label as the left hand side of the production that generates this terminal, in this case the production is `Det -> that` so the label is `Det`) and then we label `[0,2]`. \n",
    "\n",
    "Equivalently, we can construct an `(n+1) x (n+1)` matrix whose `(i,j)th` element contains the label for span `[i,j]`, then fill the upper triangular portion of this matrix, column by column, starting from bottom of the column to top. Furtehrmore, since each span can be thought of as being composed by two constituents (because the productions are binary), we also need to consider all possible splits at position `k` where `i<k<j`. Because of the way we are filling column by column from bottom to top, the labels for the the two constituents of each splits will already have been computed. Say the labels for a split are `B C`, then if we find a production `A -> B C`, then we append the label `A` to cell `(i,j)`, i.e. we can have multiple labels inside each cell. In addition to storing the label, we also store pointers to the cells containing the two consituents. \n",
    "\n",
    "What makes this a dynamic programming algorithm is this systematic way of filling the matrix involves combining smaller consitutents into bigger ones. Then a valid parse exists if we end up with a label of `S` in the `(0,n)th` entry in the matrix which is the last one to be filled. To obtain the parse trees, we then have to perform `backtracing` to recursively retreive the consituentes via their pointers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
