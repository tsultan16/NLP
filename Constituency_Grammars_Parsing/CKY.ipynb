{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CKY Parsing Algorithm\n",
    "\n",
    "The `CKY` algorithm is a `dynamic programming algorithm` for efficiently creating all possible parse trees for a given sentence and context-free grammar. It requires the grammar to be in `Chomsky Normal Form (CNF)`, i.e. each production is either of the form $A \\to B C$ or $A \\to a$, where $A,B,C \\in N$ and $a \\in \\Sigma$.\n",
    "\n",
    "We will first define our grammar (borrowed from Figure 17.8, Jurafsky-Martin textbook), convert it to CNF and then implement the CKY parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grammar\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP | Aux NP VP | VP \n",
    "    NP -> Det Nom | PropN | Pronoun \n",
    "    Nom -> Noun | Nom Noun | Nom PP\n",
    "    VP -> Verb | Verb NP | Verb NP PP | Verb PP | VP PP\n",
    "    PP -> Prep NP\n",
    "    Det -> 'that' | 'this' | 'the' | 'a' \n",
    "    Noun -> 'book' | 'flight' | 'meal' | 'money'\n",
    "    Verb -> 'book' | 'include' | 'prefer'\n",
    "    Pronoun -> 'I' | 'she' | 'me'\n",
    "    PropN -> 'Houston' | 'NWA'\n",
    "    Aux -> 'does'\n",
    "    Prep -> 'from' | 'to' | 'on' | 'near' | 'through'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert this grammar to CNF, we will first binarize all the productions:\n",
    "\n",
    "`S -> Aux NP VP` becomes `S -> X1 VP` and `X1 -> Aux NP`\n",
    "\n",
    "`VP -> Verb NP PP` becomes `VP -> X2 PP` and `X2 -> Verb NP`\n",
    "\n",
    "\n",
    "Then we convert the unit production:\n",
    "\n",
    "S -> VP \n",
    "=> S -> Verb | Verb NP | X2 PP | Verb PP | VP PP \n",
    "=> `S -> 'book' | 'include' | 'prefer' | Verb NP | X2 PP | Verb PP | VP PP`\n",
    "\n",
    "NP -> Det Nom | PropN | Pronoun \n",
    "=> `NP -> Det Nom | 'Houston' | 'NWA' | 'I' | 'she' | 'me'` \n",
    "\n",
    "Nom -> Noun | Nom Noun | Nom PP\n",
    "=> `Nom -> 'book' | 'flight' | 'meal' | 'money' | Nom Noun | Nom PP`\n",
    "\n",
    "VP -> Verb | Verb NP | Verb NP PP | Verb PP | VP PP\n",
    "=> `VP -> 'book' | 'include' | 'prefer' | Verb NP | Verb NP PP | Verb PP | VP PP`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grammar in CNF\n",
    "grammar_CNF = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP | X1 VP | 'book' | 'include' | 'prefer' | Verb NP | X2 PP | Verb PP | VP PP \n",
    "    X1 -> Aux NP\n",
    "    NP -> Det Nom \n",
    "    NP -> 'Houston' | 'NWA' | 'I' | 'she' | 'me' \n",
    "    Nom -> Nom Noun | Nom PP\n",
    "    Nom -> 'book' | 'flight' | 'meal' | 'money'\n",
    "    VP -> Verb NP | X2 PP | Verb PP | VP PP\n",
    "    VP -> 'book' | 'include' | 'prefer'\n",
    "    X2 -> Verb NP                              \n",
    "    PP -> Prep NP\n",
    "    Det -> 'that' | 'this' | 'the' | 'a' \n",
    "    Noun -> 'book' | 'flight' | 'meal' | 'money'\n",
    "    Verb -> 'book' | 'include' | 'prefer'\n",
    "    Pronoun -> 'I' | 'she' | 'me'\n",
    "    PropN -> 'Houston' | 'NWA'\n",
    "    Aux -> 'does'\n",
    "    Prep -> 'from' | 'to' | 'on' | 'near' | 'through'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S -> NP VP\n",
      "\tLHS: S\n",
      "\tRHS: (NP, VP)\n",
      "S -> X1 VP\n",
      "\tLHS: S\n",
      "\tRHS: (X1, VP)\n",
      "S -> 'book'\n",
      "\tLHS: S\n",
      "\tRHS: ('book',)\n",
      "S -> 'include'\n",
      "\tLHS: S\n",
      "\tRHS: ('include',)\n",
      "S -> 'prefer'\n",
      "\tLHS: S\n",
      "\tRHS: ('prefer',)\n",
      "S -> Verb NP\n",
      "\tLHS: S\n",
      "\tRHS: (Verb, NP)\n",
      "S -> X2 PP\n",
      "\tLHS: S\n",
      "\tRHS: (X2, PP)\n",
      "S -> Verb PP\n",
      "\tLHS: S\n",
      "\tRHS: (Verb, PP)\n",
      "S -> VP PP\n",
      "\tLHS: S\n",
      "\tRHS: (VP, PP)\n",
      "X1 -> Aux NP\n",
      "\tLHS: X1\n",
      "\tRHS: (Aux, NP)\n",
      "NP -> Det Nom\n",
      "\tLHS: NP\n",
      "\tRHS: (Det, Nom)\n",
      "NP -> 'Houston'\n",
      "\tLHS: NP\n",
      "\tRHS: ('Houston',)\n",
      "NP -> 'NWA'\n",
      "\tLHS: NP\n",
      "\tRHS: ('NWA',)\n",
      "NP -> 'I'\n",
      "\tLHS: NP\n",
      "\tRHS: ('I',)\n",
      "NP -> 'she'\n",
      "\tLHS: NP\n",
      "\tRHS: ('she',)\n",
      "NP -> 'me'\n",
      "\tLHS: NP\n",
      "\tRHS: ('me',)\n",
      "Nom -> Nom Noun\n",
      "\tLHS: Nom\n",
      "\tRHS: (Nom, Noun)\n",
      "Nom -> Nom PP\n",
      "\tLHS: Nom\n",
      "\tRHS: (Nom, PP)\n",
      "Nom -> 'book'\n",
      "\tLHS: Nom\n",
      "\tRHS: ('book',)\n",
      "Nom -> 'flight'\n",
      "\tLHS: Nom\n",
      "\tRHS: ('flight',)\n",
      "Nom -> 'meal'\n",
      "\tLHS: Nom\n",
      "\tRHS: ('meal',)\n",
      "Nom -> 'money'\n",
      "\tLHS: Nom\n",
      "\tRHS: ('money',)\n",
      "VP -> Verb NP\n",
      "\tLHS: VP\n",
      "\tRHS: (Verb, NP)\n",
      "VP -> X2 PP\n",
      "\tLHS: VP\n",
      "\tRHS: (X2, PP)\n",
      "VP -> Verb PP\n",
      "\tLHS: VP\n",
      "\tRHS: (Verb, PP)\n",
      "VP -> VP PP\n",
      "\tLHS: VP\n",
      "\tRHS: (VP, PP)\n",
      "VP -> 'book'\n",
      "\tLHS: VP\n",
      "\tRHS: ('book',)\n",
      "VP -> 'include'\n",
      "\tLHS: VP\n",
      "\tRHS: ('include',)\n",
      "VP -> 'prefer'\n",
      "\tLHS: VP\n",
      "\tRHS: ('prefer',)\n",
      "X2 -> Verb NP\n",
      "\tLHS: X2\n",
      "\tRHS: (Verb, NP)\n",
      "PP -> Prep NP\n",
      "\tLHS: PP\n",
      "\tRHS: (Prep, NP)\n",
      "Det -> 'that'\n",
      "\tLHS: Det\n",
      "\tRHS: ('that',)\n",
      "Det -> 'this'\n",
      "\tLHS: Det\n",
      "\tRHS: ('this',)\n",
      "Det -> 'the'\n",
      "\tLHS: Det\n",
      "\tRHS: ('the',)\n",
      "Det -> 'a'\n",
      "\tLHS: Det\n",
      "\tRHS: ('a',)\n",
      "Noun -> 'book'\n",
      "\tLHS: Noun\n",
      "\tRHS: ('book',)\n",
      "Noun -> 'flight'\n",
      "\tLHS: Noun\n",
      "\tRHS: ('flight',)\n",
      "Noun -> 'meal'\n",
      "\tLHS: Noun\n",
      "\tRHS: ('meal',)\n",
      "Noun -> 'money'\n",
      "\tLHS: Noun\n",
      "\tRHS: ('money',)\n",
      "Verb -> 'book'\n",
      "\tLHS: Verb\n",
      "\tRHS: ('book',)\n",
      "Verb -> 'include'\n",
      "\tLHS: Verb\n",
      "\tRHS: ('include',)\n",
      "Verb -> 'prefer'\n",
      "\tLHS: Verb\n",
      "\tRHS: ('prefer',)\n",
      "Pronoun -> 'I'\n",
      "\tLHS: Pronoun\n",
      "\tRHS: ('I',)\n",
      "Pronoun -> 'she'\n",
      "\tLHS: Pronoun\n",
      "\tRHS: ('she',)\n",
      "Pronoun -> 'me'\n",
      "\tLHS: Pronoun\n",
      "\tRHS: ('me',)\n",
      "PropN -> 'Houston'\n",
      "\tLHS: PropN\n",
      "\tRHS: ('Houston',)\n",
      "PropN -> 'NWA'\n",
      "\tLHS: PropN\n",
      "\tRHS: ('NWA',)\n",
      "Aux -> 'does'\n",
      "\tLHS: Aux\n",
      "\tRHS: ('does',)\n",
      "Prep -> 'from'\n",
      "\tLHS: Prep\n",
      "\tRHS: ('from',)\n",
      "Prep -> 'to'\n",
      "\tLHS: Prep\n",
      "\tRHS: ('to',)\n",
      "Prep -> 'on'\n",
      "\tLHS: Prep\n",
      "\tRHS: ('on',)\n",
      "Prep -> 'near'\n",
      "\tLHS: Prep\n",
      "\tRHS: ('near',)\n",
      "Prep -> 'through'\n",
      "\tLHS: Prep\n",
      "\tRHS: ('through',)\n",
      "Non-terminals: {NP, PP, Pronoun, S, PropN, Det, Noun, Verb, Prep, X2, Aux, X1, Nom, VP}\n",
      "Terminals: {'that', 'does', 'money', 'this', 'flight', 'the', 'from', 'I', 'a', 'include', 'prefer', 'near', 'book', 'me', 'meal', 'Houston', 'on', 'NWA', 'to', 'through', 'she'}\n"
     ]
    }
   ],
   "source": [
    "# show all the productions, terminal and non-terminal symbols\n",
    "terminals = set()\n",
    "non_terminals = set()\n",
    "for production in grammar_CNF.productions():\n",
    "    print(production)\n",
    "    print(f\"\\tLHS: {production.lhs()}\")\n",
    "    print(f\"\\tRHS: {production.rhs()}\")\n",
    "    non_terminals.add(production.lhs())\n",
    "    for symbol in production.rhs():\n",
    "        if nltk.grammar.is_terminal(symbol):\n",
    "            terminals.add(symbol)\n",
    "        else:\n",
    "            non_terminals.add(symbol)\n",
    "\n",
    "print(f\"Non-terminals: {non_terminals}\")\n",
    "print(f\"Terminals: {terminals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CKY is a dynamic programming algorithm for finding valid parse trees for a given sentence. It requires the grammar to be in CFN so that each production rule is binary. It has two steps: 1) `Recognition` and 2) `Backtracking`\n",
    "\n",
    "The `recognition` involves considering each possible span in a sentence and labelling it with an appropriate constituent from the grammar. First, we define `fenceposts` which are positions between adjacent words in the sentence. For a sentence with `n` words, position `0` is to the left of the first word and position `n` is to the right of the last word. Then we define `span [i,j]` as the words between positions `i` and `j`,  e.g. for the sentence, `0 Book 1 that 2 flight 3`, span `[1,3]` denotes `that flight`. \n",
    "\n",
    "Then for each word in the sentence (in order starting from first), we consider all spans that have right fencepost fixed at the end of that word and left fencepost which starts to the left of that word and advances one step at a time until reaching position `0`, so e.g. for the word `that`, we will first consider the span `[1,2]`, label it (since this is a single word, i.e. a terminal symbol, we assign the label as the left hand side of the production that generates this terminal, in this case the production is `Det -> that` so the label is `Det`) and then we label `[0,2]`. \n",
    "\n",
    "Equivalently, we can construct an `(n+1) x (n+1)` matrix whose `(i,j)th` element contains the label for span `[i,j]`, then fill the `upper-triangular portion` of this matrix, column by column, starting from bottom of the column to top. Furtehrmore, since each span can be thought of as being composed by two constituents (because the productions are binary), we also need to consider all possible splits at position `k` where `i<k<j`. Because of the way we are filling column by column from bottom to top, the labels for the the two constituents of each splits will already have been computed. Say the labels for a split are `B C`, then if we find a production `A -> B C`, then we append the label `A` to cell `(i,j)`, i.e. we can have multiple labels inside each cell. In addition to storing the label, we also store pointers to the cells containing the two consituents. \n",
    "\n",
    "What makes this a dynamic programming algorithm is this systematic way of filling the matrix involves combining smaller consitutents into bigger ones. Then a valid parse exists if we end up with a label of `S` in the `(0,n)th` entry in the matrix which is the last one to be filled. To obtain the parse trees, we then have to perform `backtracing` from each `S` label in the `(0,n)` cell to recursively retreive the consituents via their pointers.\n",
    "\n",
    "Now lets implement this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CKY_parse(words, grammar):\n",
    "    table = defaultdict(list)\n",
    "    # base case: fill the super diagonal of the table\n",
    "    for j in range(1, len(words)+1):\n",
    "        for production in grammar.productions():\n",
    "            if production.rhs() == (words[j-1],):\n",
    "                table[(j-1,j)].append((production.lhs(), (None, None, words[j-1]), None))\n",
    "\n",
    "    # print table\n",
    "    print(f\"Table base case:\")\n",
    "    for i in range(len(words)):\n",
    "        for j in range(len(words)+1):\n",
    "            print(f\"{[item[0] for item in table[(i,j)]]}\\t\", end=\"\")\n",
    "        print()\n",
    "\n",
    "    ############## \n",
    "    # Recognition\n",
    "    ##############\n",
    "\n",
    "    # iterate over columns \n",
    "    for j in range(1, len(words)+1):\n",
    "        # fill from bottom to top of column\n",
    "        for i in range(j-2, -1, -1):\n",
    "            # iterate over constituent splits for span [i,j]\n",
    "            #print(f\"i: {i}, j: {j}\")\n",
    "            for k in range(i+1,j):\n",
    "                #print(f\"k :{k}\")\n",
    "                # get consituent spans [i,k] and [j,k]\n",
    "                left = table[(i,k)] \n",
    "                right = table[(k,j)]         \n",
    "                #print(f\"left constituents: {left}\")\n",
    "                #print(f\"right constituents: {right}\")\n",
    "            \n",
    "                # iterate over all constituent label combinations\n",
    "                for B,_,_ in left:\n",
    "                    for C,_,_ in right:\n",
    "                        for production in grammar.productions():\n",
    "                            if production.rhs() == (B,C):\n",
    "                                A = production.lhs()\n",
    "                                back_pointer_B = (i,k,B)\n",
    "                                back_pointer_C = (k,j,C) \n",
    "                                table[(i,j)].append((A, back_pointer_B, back_pointer_C))\n",
    "\n",
    "    print(\"\\nTable after completing recognition phase:\")\n",
    "    # print table\n",
    "    for i in range(len(words)):\n",
    "        for j in range(len(words)+1):\n",
    "            print(f\"{[item[0] for item in table[(i,j)]]}\\t\", end=\"\")\n",
    "        print()\n",
    "\n",
    "    #print(f\"Labels for span [0,n]:\")                        \n",
    "    #for label in table[(0,len(words))]:                           \n",
    "    #    print(f\"\\t{label}\")\n",
    "\n",
    "    ############## \n",
    "    # Backtracing\n",
    "    ##############\n",
    "    def trace_back(label, constituents):\n",
    "        #print(f\"label: {label}, coinstituents: {constituents}\")\n",
    "        if constituents[1] == None:\n",
    "            return nltk.Tree(str(label), [constituents[0][-1]])\n",
    "        else:\n",
    "            # create and add child nodes to tree\n",
    "            left_constituent = constituents[0]\n",
    "            right_constituent = constituents[1]\n",
    "            \n",
    "            # find constituents of left child\n",
    "            for constituent_label in table[(left_constituent[0],left_constituent[1])]:\n",
    "                if str(constituent_label[0]) == str(left_constituent[2]):\n",
    "                    left_child_constituents = constituent_label[1:]\n",
    "                    break\n",
    "            # find right child constituents\n",
    "            for constituent_label in table[(right_constituent[0],right_constituent[1])]:\n",
    "                if str(constituent_label[0]) == str(right_constituent[2]):\n",
    "                    right_child_constituents = constituent_label[1:]\n",
    "                    break\n",
    "            # recurse on children\n",
    "            return nltk.Tree(str(label), [trace_back(left_constituent[2], left_child_constituents), trace_back(right_constituent[2], right_child_constituents)])    \n",
    "\n",
    "\n",
    "    for label in table[(0,len(words))]:\n",
    "        if str(label[0]) == \"S\":\n",
    "            print(\"\\nFound a parse!\")\n",
    "            # create parse tree root\n",
    "            constituents = label[1:]\n",
    "            # trace back the parse tree\n",
    "            tree = trace_back(label[0], constituents)\n",
    "            tree.pretty_print() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table base case:\n",
      "[]\t[S, Nom, VP, Noun, Verb]\t[]\t[]\t[]\t[]\t\n",
      "[]\t[]\t[Det]\t[]\t[]\t[]\t\n",
      "[]\t[]\t[]\t[Nom, Noun]\t[]\t[]\t\n",
      "[]\t[]\t[]\t[]\t[Prep]\t[]\t\n",
      "[]\t[]\t[]\t[]\t[]\t[NP, PropN]\t\n",
      "\n",
      "Table after completing recognition phase:\n",
      "[]\t[S, Nom, VP, Noun, Verb]\t[]\t[S, VP, X2]\t[]\t[S, VP, X2, S, VP, S, VP]\t\n",
      "[]\t[]\t[Det]\t[NP]\t[]\t[NP]\t\n",
      "[]\t[]\t[]\t[Nom, Noun]\t[]\t[Nom]\t\n",
      "[]\t[]\t[]\t[]\t[Prep]\t[PP]\t\n",
      "[]\t[]\t[]\t[]\t[]\t[NP, PropN]\t\n",
      "\n",
      "Found a parse!\n",
      "           S                           \n",
      "  _________|_____                       \n",
      " |               NP                    \n",
      " |     __________|_____                 \n",
      " |    |               Nom              \n",
      " |    |     ___________|_____           \n",
      " |    |    |                 PP        \n",
      " |    |    |            _____|_____     \n",
      "Verb Det  Nom         Prep         NP  \n",
      " |    |    |           |           |    \n",
      "book the flight     through     Houston\n",
      "\n",
      "\n",
      "Found a parse!\n",
      "               S                       \n",
      "       ________|_____________           \n",
      "      VP                     |         \n",
      "  ____|___                   |          \n",
      " |        NP                 PP        \n",
      " |     ___|____         _____|_____     \n",
      "Verb Det      Nom     Prep         NP  \n",
      " |    |        |       |           |    \n",
      "book the     flight through     Houston\n",
      "\n",
      "\n",
      "Found a parse!\n",
      "               S                       \n",
      "       ________|_____________           \n",
      "      X2                     |         \n",
      "  ____|___                   |          \n",
      " |        NP                 PP        \n",
      " |     ___|____         _____|_____     \n",
      "Verb Det      Nom     Prep         NP  \n",
      " |    |        |       |           |    \n",
      "book the     flight through     Houston\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = [\"book\", \"the\", \"flight\", \"through\", \"Houston\"]\n",
    "tree = CKY_parse(words, grammar_CNF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
