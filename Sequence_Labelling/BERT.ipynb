{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT based Sequence Labeller\n",
    "\n",
    "We've explored training HMM (Viterbi) and RNN-based POS (part of speech) taggers on tagged sentences from the Stanford treebank dataset. We saw that the HMM tagger had a validation accuracy of about 90% and the RNN based tagger had about 91%. We will now try a different type of neural approach. For the RNN, recall that we used pretrained GloVe embeddings to represent the words in a sentence. Since the meaning of words in a sentence can be ambiguous, we should use contextualized vector representations of words instead of fixed GloVe word embeddings to overcome this problem of word sense. Pretrained BERT models are perfect for this task because they can be used to extract contextualized word embedding. \n",
    "\n",
    "In this notebook, we will finetune a BERT model on the POS tagging task. Since BERT uses subword tokenization and POS labels are assigned to whole words, we need to figure out a way of assigning labels to the subword tokens. A simple approach is to assign the POS label of a word to the first subword in the sequence of subwords corresponding to that word, then assign a special tag 'X' to the remaining subwords, which indicates a continuation of the preceding POS label. e.g.\n",
    "\n",
    "`(spokesman, NN)` --> {`(spokes, NN)`, `(##man, X)`}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtanzids\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizerFast, RobertaModel, get_linear_schedule_with_warmup\n",
    "from nltk.corpus import treebank\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "import wandb\n",
    "import os\n",
    "import random\n",
    "\n",
    "wandb.login()\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences:  3914\n",
      "Longest sentence length: 271\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the POS tagged corpus, 3914 tagged sentences\n",
    "corpus = list(treebank.tagged_sents())\n",
    "# shuffle the corpus\n",
    "random.seed(42)\n",
    "random.shuffle(corpus)\n",
    "\n",
    "print(\"Number of sentences: \", len(corpus))\n",
    "print(f\"Longest sentence length: {max([len(s) for s in corpus])}\")\n",
    "\n",
    "# create training-validation splits\n",
    "num_train = int(0.9 * len(corpus))\n",
    "train_corpus = corpus[:num_train]\n",
    "val_corpus = corpus[num_train:]\n",
    "\n",
    " # get the sentences and labels\n",
    "train_sentences = [[elem[0] for elem in s] for s in train_corpus]\n",
    "train_pos_labels = [[elem[1] for elem in s] for s in train_corpus]\n",
    "val_sentences = [[elem[0] for elem in s] for s in val_corpus]\n",
    "val_pos_labels = [[elem[1] for elem in s] for s in val_corpus]\n",
    "\n",
    "# define special continuation tag\n",
    "continuation_tag = \"X\"\n",
    "# get tag set\n",
    "tags = sorted([continuation_tag] + list(set([elem[1] for s in corpus for elem in s])))\n",
    "tag2idx = {tag:idx for idx, tag in enumerate(tags)}\n",
    "\n",
    "# histogram of sent_lens\n",
    "import matplotlib.pyplot as plt\n",
    "sent_lens = [len(s) for s in corpus] \n",
    "plt.hist(sent_lens, bins=50)\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set tokenizer parallelism to False\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  \n",
    "\n",
    "class Treebank(Dataset):\n",
    "    def __init__(self, sentences, pos_labels, tag2idx, continuation_tag = \"X\", block_size=128):\n",
    "        self.block_size = block_size\n",
    "        self.sentences = sentences\n",
    "        self.pos_labels = pos_labels\n",
    "        self.tag2idx = tag2idx\n",
    "        self.continuation_tag = continuation_tag\n",
    "        self.tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base', add_prefix_space=True)\n",
    "\n",
    "    @property\n",
    "    def num_tags(self):\n",
    "        return len(self.tags)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get sentence and labels\n",
    "        sentence = self.sentences[idx]\n",
    "        labels = self.pos_labels[idx]\n",
    "        # tokenize the sentence\n",
    "        input_encoding = self.tokenizer.encode_plus(sentence, is_split_into_words=True, return_offsets_mapping=False, padding=False, truncation=False, add_special_tokens=True)\n",
    "        input_idx = input_encoding['input_ids']\n",
    "        word_ids = input_encoding.word_ids()\n",
    "\n",
    "        # assign labels to subword tokens (we use -100 as label for special tokens)\n",
    "        labels_subword = [-100]\n",
    "        for i in range(len(word_ids)):\n",
    "            if word_ids[i] != None:\n",
    "                if word_ids[i] != word_ids[i-1]:\n",
    "                    labels_subword.append(self.tag2idx[labels[word_ids[i]]])\n",
    "                else:\n",
    "                    labels_subword.append(self.tag2idx[self.continuation_tag]) \n",
    "        labels_subword.append(-100)  \n",
    "\n",
    "        # truncate the input sequence if it is too long\n",
    "        if len(input_idx) > self.block_size:\n",
    "            input_idx = input_idx[:self.block_size-1] + [input_idx[-1]]\n",
    "            labels_subword = labels_subword[:self.block_size-1] + [labels_subword[-1]]\n",
    "\n",
    "        # add padding \n",
    "        input_idx = input_idx + [self.tokenizer.pad_token_id] * (self.block_size - len(input_idx))    \n",
    "        labels_subword = labels_subword + [-100] * (self.block_size - len(labels_subword))    \n",
    "        # create attention mask \n",
    "        input_attn_mask = [1 if idx != self.tokenizer.pad_token_id else 0 for idx in input_idx]\n",
    "\n",
    "        # convert to tensors\n",
    "        input_idx = torch.tensor(input_idx)\n",
    "        labels_subword = torch.tensor(labels_subword)\n",
    "        input_attn_mask = torch.tensor(input_attn_mask) \n",
    "        \n",
    "        return input_idx, input_attn_mask, labels_subword   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "train_dataset = Treebank(train_sentences, train_pos_labels, tag2idx, block_size=block_size)\n",
    "val_dataset = Treebank(val_sentences, val_pos_labels, tag2idx, block_size=block_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the POS tagger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTPOS(torch.nn.Module):\n",
    "    def __init__(self, num_classes, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        # load pretrained BERT model\n",
    "        #self.bert_encoder = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.bert_encoder = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        # define classifier head\n",
    "        self.classifier_head = torch.nn.Linear(768, num_classes)\n",
    "        # make sure BERT parameters are trainable\n",
    "        for param in self.bert_encoder.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, input_idx, input_attn_mask, targets=None):\n",
    "        # compute BERT embeddings for input tokens\n",
    "        bert_output = self.bert_encoder(input_idx, attention_mask=input_attn_mask)\n",
    "        bert_output = self.dropout(bert_output.last_hidden_state) # shape: (batch_size, block_size, hidden_size)\n",
    "        # compute output logits\n",
    "        logits = self.classifier_head(bert_output) # shape: (batch_size, block_size, num_classes)\n",
    "        loss = None  \n",
    "        if targets is not None:\n",
    "            # reshape logits to (batch_size * block_size, num_classes)\n",
    "            logits = logits.view(-1, logits.shape[-1])\n",
    "            # reshape targets to (batch_size * block_size)\n",
    "            targets = targets.view(-1)\n",
    "            # compute cross-entropy loss\n",
    "            loss = F.cross_entropy(logits, targets, ignore_index=-100)\n",
    "        return logits, loss\n",
    "    \n",
    "\n",
    "# training loop\n",
    "def train(model, optimizer, train_dataloader, val_dataloader, scheduler=None, device=\"cpu\", num_epochs=10, val_every=100, save_every=None, log_metrics=None):\n",
    "    avg_loss = 0\n",
    "    train_acc = 0\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    model.train()\n",
    "    # reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    for epoch in range(num_epochs):\n",
    "        num_correct = 0\n",
    "        num_total = 0\n",
    "        pbar = tqdm(train_dataloader, desc=\"Epochs\")\n",
    "        for i, batch in enumerate(pbar):\n",
    "            input_idx, input_attn_mask, targets = batch\n",
    "            # move batch to device\n",
    "            input_idx, input_attn_mask, targets = input_idx.to(device), input_attn_mask.to(device), targets.to(device)\n",
    "            # forward pass\n",
    "            logits, loss = model(input_idx, input_attn_mask, targets)\n",
    "            # reset gradients\n",
    "            optimizer.zero_grad()\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            # optimizer step\n",
    "            optimizer.step()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                    scheduler.step()\n",
    "\n",
    "            avg_loss = 0.9* avg_loss + 0.1*loss.item()\n",
    "            B, _ = input_idx.shape\n",
    "            # reshape logits to (batch_size * block_size, num_classes)\n",
    "            logits = logits.view(-1, logits.shape[-1])\n",
    "            y_pred = logits.argmax(dim=-1).view(-1) # shape (batch_size * block_size,)\n",
    "            # reshape targets\n",
    "            targets = targets.view(-1) # shape (batch_size * block_size,)\n",
    "            # target mask\n",
    "            target_mask = (targets != -100)\n",
    "            # compute accuracy\n",
    "            num_correct += y_pred[target_mask].eq(targets[target_mask]).sum().item()\n",
    "            num_total += target_mask.sum().item()\n",
    "            train_acc = num_correct / num_total        \n",
    "\n",
    "            if val_every is not None:\n",
    "                if i%val_every == 0:\n",
    "                    # compute validation loss\n",
    "                    val_loss, val_acc = validation(model, val_dataloader, device=device)\n",
    "                    pbar.set_description(f\"Epoch {epoch + 1}, EMA Train Loss: {avg_loss:.3f}, Train Accuracy: {train_acc: .3f}, Val Loss: {val_loss: .3f}, Val Accuracy: {val_acc: .3f}\")  \n",
    "\n",
    "            pbar.set_description(f\"Epoch {epoch + 1}, EMA Train Loss: {avg_loss:.3f}, Train Accuracy: {train_acc: .3f}, Val Loss: {val_loss: .3f}, Val Accuracy: {val_acc: .3f}\")  \n",
    "\n",
    "            if log_metrics:\n",
    "                metrics = {\"Batch loss\":loss.item(), \"Moving Avg Loss\":avg_loss, \"Train Accuracy\":train_acc, \"Val Loss\": val_loss, \"Val Accuracy\":val_acc}\n",
    "                log_metrics(metrics)\n",
    "\n",
    "        if save_every is not None:\n",
    "            if (epoch+1) % save_every == 0:\n",
    "                save_model_checkpoint(model, optimizer, epoch, avg_loss)\n",
    "\n",
    "\n",
    "def validation(model, val_dataloader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    val_losses = torch.zeros(len(val_dataloader))\n",
    "    with torch.no_grad():\n",
    "        num_correct = 0\n",
    "        num_total = 0\n",
    "        for i,batch in enumerate(val_dataloader):\n",
    "            input_idx, input_attn_mask, targets = batch\n",
    "            input_idx, input_attn_mask, targets = input_idx.to(device), input_attn_mask.to(device), targets.to(device)\n",
    "            logits, loss = model(input_idx, input_attn_mask, targets)\n",
    "            B, _ = input_idx.shape\n",
    "            # reshape logits to (batch_size * block_size, num_classes)\n",
    "            logits = logits.view(-1, logits.shape[-1])\n",
    "            y_pred = logits.argmax(dim=-1).view(-1) # shape (batch_size * block_size,)\n",
    "            # reshape targets\n",
    "            targets = targets.view(-1) # shape (batch_size * block_size,)\n",
    "            # target mask\n",
    "            target_mask = (targets != -100)\n",
    "            # compute accuracy\n",
    "            num_correct += y_pred[target_mask].eq(targets[target_mask]).sum().item()\n",
    "            num_total += target_mask.sum().item()\n",
    "            val_losses[i] = loss.item()\n",
    "    model.train()\n",
    "    val_loss = val_losses.mean().item()\n",
    "    val_accuracy = num_correct / num_total\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "\n",
    "def save_model_checkpoint(model, optimizer, epoch=None, loss=None, filename='BERT_tagger_checkpoint.pth'):\n",
    "    # Save the model and optimizer state_dict\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }\n",
    "    # Save the checkpoint to a file\n",
    "    torch.save(checkpoint, filename)\n",
    "    print(f\"Saved model checkpoint!\")\n",
    "\n",
    "\n",
    "\n",
    "def load_model_checkpoint(model, optimizer=None,  filename='BERT_tagger_checkpoint.pth'):\n",
    "    checkpoint = torch.load(filename)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(\"Loaded model from checkpoint!\")\n",
    "    if optimizer:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        model.train()\n",
    "        return model, optimizer          \n",
    "    else:\n",
    "        return model        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in transformer network: 124.681775 M\n",
      "RAM used: 2751.11 MB\n"
     ]
    }
   ],
   "source": [
    "B = 16\n",
    "DEVICE = \"cuda\"\n",
    "learning_rate = 1e-5\n",
    "epochs = 5\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=B, shuffle=True, pin_memory=True, num_workers=2)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=B, shuffle=True, pin_memory=True, num_workers=2)\n",
    "\n",
    "# model with finetuning disabled\n",
    "model = BERTPOS(num_classes=len(tags) ,dropout_rate=0.1).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "total_steps = len(train_dataloader) * epochs \n",
    "warmup_steps = int(len(train_dataloader) * 0.1 *  epochs) \n",
    "scheduler = None #get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "#model, optimizer = load_model_checkpoint(model, optimizer)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters in transformer network: {num_params/1e6} M\")\n",
    "print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tanzid/Code/NLP/Sequence_Labelling/wandb/run-20240128_011827-apqizohg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tanzids/BERT%20POS%20Tagger/runs/apqizohg' target=\"_blank\">daily-breeze-6</a></strong> to <a href='https://wandb.ai/tanzids/BERT%20POS%20Tagger' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tanzids/BERT%20POS%20Tagger' target=\"_blank\">https://wandb.ai/tanzids/BERT%20POS%20Tagger</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tanzids/BERT%20POS%20Tagger/runs/apqizohg' target=\"_blank\">https://wandb.ai/tanzids/BERT%20POS%20Tagger/runs/apqizohg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project=\"BERT POS Tagger\", \n",
    "    config={\n",
    "        \"model\": \"RoBERTa\",\n",
    "        \"learning_rate\": learning_rate, \n",
    "        \"epochs\": 5,\n",
    "        \"batch_size\": B, \n",
    "        \"corpus\": \"Stanford Treebank\"},)   \n",
    "\n",
    "def log_metrics(metrics):\n",
    "    wandb.log(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, EMA Train Loss: 0.417, Train Accuracy:  0.652, Val Loss:  0.286, Val Accuracy:  0.946:  69%|██████▉   | 152/221 [00:36<00:16,  4.13it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_metrics\u001b[49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[0;32mIn[5], line 60\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_dataloader, val_dataloader, scheduler, device, num_epochs, val_every, save_every, log_metrics)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scheduler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m         scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 60\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m\u001b[38;5;241m*\u001b[39m avg_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.1\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m B, _ \u001b[38;5;241m=\u001b[39m input_idx\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# reshape logits to (batch_size * block_size, num_classes)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, optimizer, train_dataloader, val_dataloader, device=DEVICE, num_epochs=epochs, scheduler=scheduler, save_every=None, val_every=30, log_metrics=log_metrics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
