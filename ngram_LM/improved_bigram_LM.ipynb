{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will address some issues with our vanilla bigram model implementation One is out of vocabulary tokens and the other is bigrams that are never observed in the training data. We will add a special `<UNK>` token to our vocabulary to address out of vocabulary words. For the zero bigram count problem, we will explore some smoothing technique.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bigram_LM():\n",
    "\n",
    "    def __init__(self, count_threshold=2, k=0.1):\n",
    "        self.count_threshold = count_threshold \n",
    "        self.k = k\n",
    "        self.bigram_counts = None\n",
    "        self.unigram_counts = None\n",
    "        self.vocab = None\n",
    "        self.word2idx = None\n",
    "        self.bigram_probs = None\n",
    "        self.num_sentences = None\n",
    "        self.unk_token = '<UNK>'\n",
    "\n",
    "    def train(self, sentences):\n",
    "        self.num_sentences = len(sentences)\n",
    "        self.vocab, self.unigram_counts, self.bigram_counts = self.get_counts(sentences)\n",
    "        self.vocab = list(self.unigram_counts.keys())\n",
    "        self.word2idx = {word:i for i,word in enumerate(self.vocab)}\n",
    "        self.compute_probs()\n",
    "        print(\"Training complete!\")         \n",
    "\n",
    "    def get_counts(self, sentences):\n",
    "        # collect unigram counts \n",
    "        print(\"Collecting unigram counts...\")\n",
    "        unigram_counts = Counter()\n",
    "        for s in sentences:\n",
    "            for word in s:\n",
    "                unigram_counts[word] += 1 \n",
    "        \n",
    "        # remove all words that have count below the threshold    \n",
    "        print(\"Constructing vocab...\")     \n",
    "        for w in list(unigram_counts.keys()):\n",
    "            if unigram_counts[w] < self.count_threshold:\n",
    "                unigram_counts.pop(w)\n",
    "        # construct vocab \n",
    "        vocab = [self.unk_token] + sorted(list(unigram_counts.keys()))            \n",
    "        \n",
    "        # replace all oov tokens in training sentences with <UNK>\n",
    "        print(\"Replacing with oov tokens in training data...\")\n",
    "        sentences_unk = []\n",
    "        for s in sentences:\n",
    "            sent = []\n",
    "            for word in s:\n",
    "                if word in vocab:\n",
    "                    sent.append(word)\n",
    "                else:\n",
    "                    sent.append(self.unk_token)\n",
    "            sentences_unk.append(sent)            \n",
    "\n",
    "        # re-collect unigram counts \n",
    "        print(\"Re-collecting unigram counts...\")\n",
    "        unigram_counts = Counter()\n",
    "        for s in sentences_unk:\n",
    "            for word in s:\n",
    "                unigram_counts[word] += 1 \n",
    "\n",
    "        # collect bigram counts\n",
    "        print(\"Collecting bigram counts...\")\n",
    "        bigram_counts = Counter()\n",
    "        for s in sentences_unk:\n",
    "            for bigram in zip(s[:-1], s[1:]):\n",
    "                bigram_counts[bigram] += 1     \n",
    "\n",
    "        return vocab, unigram_counts, bigram_counts\n",
    "    \n",
    "    def compute_probs(self):\n",
    "        print(\"Computing bigram probabilities...\")\n",
    "        bigram_probs = Counter()\n",
    "        for word1 in self.vocab:\n",
    "            probs = []\n",
    "            for word2 in self.vocab:\n",
    "                # compute P(word2|word1)\n",
    "                p = self.bg_prob(word1, word2)\n",
    "                probs.append(p)\n",
    "            bigram_probs[word1] = probs \n",
    "        self.bigram_probs = bigram_probs   \n",
    "\n",
    "    def bg_prob(self, word1, word2):\n",
    "        # addk probability\n",
    "        p = (self.bigram_counts[(word1, word2)] + self.k) / (self.unigram_counts[word1] + self.k*len(self.vocab)) \n",
    "        return p        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num sentences: 32777\n",
      "Number of training sentences: 29500\n",
      "Number of test sentences: 3277\n"
     ]
    }
   ],
   "source": [
    "# prep the training data\n",
    "with open('shakespeare.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# remove all punctuations (except for apostrophe) and escape characters from the lines, lowercase all characters\n",
    "sentences_clean = []\n",
    "for line in lines:\n",
    "    cleaned = re.sub(r\"[^\\w\\s']\",'',line).strip().lower()\n",
    "    if len(cleaned) > 0:\n",
    "        sentences_clean.append(cleaned)\n",
    "\n",
    "# tokenize the sentences (split on whitespaces) and add start and end sentence tokens\n",
    "start_token = '<s>'        \n",
    "end_token = '</s>'        \n",
    "sentences_tokenized = [[start_token]+s.split()+[end_token] for s in sentences_clean]\n",
    "print(f\"Num sentences: {len(sentences_tokenized)}\")    \n",
    "\n",
    "# now we split the data into train and test sentences\n",
    "num_sent = len(sentences_tokenized)\n",
    "num_test = int(0.1 * num_sent)\n",
    "test_idx = random.sample(range(num_sent), num_test)\n",
    "\n",
    "sentences_train = []\n",
    "sentences_test = []\n",
    "for i in range(num_sent):\n",
    "    if i not in test_idx:\n",
    "        sentences_train.append(sentences_tokenized[i])\n",
    "    else:\n",
    "        sentences_test.append(sentences_tokenized[i])    \n",
    "\n",
    "print(f\"Number of training sentences: {len(sentences_train)}\")        \n",
    "print(f\"Number of test sentences: {len(sentences_test)}\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unigram counts...\n",
      "Constructing vocab...\n",
      "Replacing with oov tokens in training data...\n",
      "Re-collecting unigram counts...\n",
      "Collecting bigram counts...\n",
      "Computing bigram probabilities...\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "model = bigram_LM()\n",
    "model.train(sentences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, n=10):\n",
    "    current_word = '<s>'\n",
    "    probs = []\n",
    "    for word in model.vocab:\n",
    "        probs.append(model.bigram_counts[(current_word, word)]/model.num_sentences)\n",
    "    current_word = random.choices(model.vocab, weights=probs, k=1)[0]\n",
    "\n",
    "    words = [current_word]\n",
    "\n",
    "    sentences = []\n",
    "    i = 0\n",
    "    for i in range(n):\n",
    "        while True:\n",
    "            # get probabilities of next word given current context, i.e P(w|w_current)\n",
    "            probs = model.bigram_probs[current_word]\n",
    "            # now sample from the vocabulry according to this distribution\n",
    "            next_word = random.choices(model.vocab, weights=probs, k=1)[0]\n",
    "            if next_word == '</s>':\n",
    "                break\n",
    "            words.append(next_word)\n",
    "            current_word = next_word\n",
    "        if len(words) > 0:    \n",
    "            sentences.append(\" \".join(words))\n",
    "        i += 1\n",
    "        words = []     \n",
    "        \n",
    "    return \"\\n\".join(sentences)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bigram probabilities...\n"
     ]
    }
   ],
   "source": [
    "model.k = 0.001\n",
    "model.compute_probs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that theme rightly knees shall whiles i thank gentle norfolk\n",
      "and practise out no\n",
      "sleep\n",
      "that cries aloud\n",
      "instinct divines\n",
      "lose him not endure her lord angelo have by action\n",
      "is to make her father\n",
      "be the stony stockings\n",
      "bashful years to bear me to marry sir stephen scroop aboard a sudden\n",
      "business\n",
      "with a <UNK> tongue\n",
      "may weep my heart and charity would\n",
      "sell it was a bloody brow orchard peace' iron wit i\n",
      "play as you shall have the common people mutinous and 'twere to taste as they come sir 'tis beauty from this\n",
      "what's in thought\n",
      "to bristol purpose dragon leg forgetfulness shall make your steed\n",
      "index aloof news unusual topmast dispatch'd against thou dost unwillingly loves faithful finds visage cherish weeds\n",
      "which i sup upon thy life him although apparent\n",
      "statue paradise bug selfsame name\n",
      "of york\n",
      "be great anchors indirectly debt\n",
      "it boots i had no cause shrift sulphurous fie fie upon your highness' shout\n",
      "quarrels as my poor boy the great part exton gripe into a <UNK> them that my state surfeit rise delphos tumbling in the deed is my lord\n",
      "ross vex'd a <UNK> graves welcomes ply his father\n",
      "was never swear it gives out\n",
      "of the first senator\n",
      "fierce doors lineaments wisdom was going pity if he\n",
      "is elder fiery clamorous smack choke ha' means\n",
      "rubs currents to <UNK> <UNK> of valour clifford and how shall have cross'd nothing privilege\n",
      "of them that clifford\n",
      "i wonder if you be content you have wine let'st extempore lucentio's father bears a bastard\n",
      "children quit bounds betwixt us that won honour lives in execution woo gazing suburbs of the duke vincentio\n"
     ]
    }
   ],
   "source": [
    "text = generate_text(model, n=100)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that increaing the smoothing factor k will result in longer sentences being generated. This is because for larger k, the probability of the `</s>` token becomes smaller. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity(model, test_sentences):\n",
    "    sum_log_probs = 0.0\n",
    "    n = 0\n",
    "    for s in test_sentences:\n",
    "        for w1,w2 in zip(s[:-1], s[1:]):\n",
    "            # replace any oov token with <UNK>\n",
    "            if w1 not in model.vocab:\n",
    "                w1 = model.unk_token    \n",
    "            if w2 not in model.vocab:\n",
    "                w2 = model.unk_token\n",
    "            sum_log_probs += np.log(model.bg_prob(w1, w2))\n",
    "            n += 1\n",
    "    sum_log_probs *= (-1/n) \n",
    "    perplexity = np.exp(sum_log_probs)\n",
    "    return perplexity  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bigram probabilities...\n",
      "\n",
      "k = 1.0\n",
      "Perplexity computed on training set: 743.252\n",
      "Perplexity computed on test set: 855.281\n",
      "Computing bigram probabilities...\n",
      "\n",
      "k = 0.1\n",
      "Perplexity computed on training set: 213.299\n",
      "Perplexity computed on test set: 383.594\n",
      "Computing bigram probabilities...\n",
      "\n",
      "k = 0.01\n",
      "Perplexity computed on training set: 92.112\n",
      "Perplexity computed on test set: 291.047\n",
      "Computing bigram probabilities...\n",
      "\n",
      "k = 0.001\n",
      "Perplexity computed on training set: 62.757\n",
      "Perplexity computed on test set: 351.426\n",
      "Computing bigram probabilities...\n",
      "\n",
      "k = 0.0001\n",
      "Perplexity computed on training set: 56.286\n",
      "Perplexity computed on test set: 550.344\n",
      "Computing bigram probabilities...\n",
      "\n",
      "k = 1e-05\n",
      "Perplexity computed on training set: 55.361\n",
      "Perplexity computed on test set: 934.920\n"
     ]
    }
   ],
   "source": [
    "# now lets compute perplexity on both the training and test data for different k values\n",
    "kvals = [1.0, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "for k in kvals:\n",
    "    model.k = k\n",
    "    model.compute_probs()\n",
    "    pp_train = compute_perplexity(model, sentences_train)\n",
    "    pp_test = compute_perplexity(model, sentences_test)\n",
    "\n",
    "    print(f\"\\nk = {k}\")\n",
    "    print(f\"Perplexity computed on training set: {pp_train:.3f}\")\n",
    "    print(f\"Perplexity computed on test set: {pp_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
